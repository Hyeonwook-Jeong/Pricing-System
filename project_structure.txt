# Project Structure
PRICING_SYSTEM/
│
├── main.py                 # Main application entry point
├── requirements.txt        # Project dependencies
├── README.md              # Project documentation
├── database               # Database
│   ├── standard           # Database - Standard
│   └── claim              # Database - Claim
│
├── gui/                   # GUI related modules
│   ├── __init__.py
│   └── tabs/             # Tab implementations
│       ├── __init__.py
│       ├── base_tab.py
│       ├── data_centre_tab.py
│       ├── performance_tab.py
│       ├── claim_tab.py
│       └── correlation_tab.py
│
└── utils/                 # Utility modules
    ├── __init__.py
    ├── data_processor.py
    └── plot_utils.py

# requirements.txt
customtkinter>=5.2.0
matplotlib>=3.7.1
numpy>=1.24.3
pandas>=2.0.2
Pillow>=9.5.0
seaborn>=0.12.2

# main.py
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import customtkinter as ctk
import pandas as pd
import traceback
from pathlib import Path
from datetime import datetime
from PIL import Image, ImageTk

from gui.tabs import (
    DataCentreTab,
    PerformanceTab,
    ClaimTab,
    CorrelationTab
)
from utils.data_processor import DataProcessor

class GeneralPricingSystem(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.data_processor = DataProcessor()
        self.setup_window()
        self.create_gui()
        
        self.current_tab = None

    def setup_window(self):
        """Initialize window settings and theme"""
        self.title("GPS - General Pricing System")
        self.geometry("1200x800")
        ctk.set_appearance_mode("dark")
        ctk.set_default_color_theme("blue")

    def create_gui(self):
        """Create the main GUI components"""
        self.create_main_container()
        self.create_header()
        self.create_status_label()
        self.create_notebook()
        self.setup_tabs()

    def create_main_container(self):
        """Create the main container frame"""
        self.main_container = ctk.CTkFrame(self)
        self.main_container.pack(fill="both", expand=True, padx=10, pady=10)

    def create_header(self):
        """Create the header with logo and program name"""
        # Header panel
        self.header_panel = ctk.CTkFrame(self.main_container, height=60, fg_color="white")
        self.header_panel.pack(fill="x", padx=5, pady=(5, 0))
        self.header_panel.pack_propagate(False)

        # Logo frame
        self.logo_frame = ctk.CTkFrame(self.header_panel, height=60, fg_color="white")
        self.logo_frame.pack(fill="x", padx=5, pady=2)
        self.logo_frame.pack_propagate(False)

        # Header content
        self.header_content = ctk.CTkFrame(self.logo_frame, height=50, fg_color="white")
        self.header_content.pack(fill="x", expand=True)

        # Compass label
        self.compass_label = ctk.CTkLabel(
            self.header_content,
            text="Compass",
            font=("Helvetica", 35, "bold"),
            text_color="black"
        )
        self.compass_label.pack(expand=True, pady=10)

        # Allianz logo
        self.load_company_logo()

    def load_company_logo(self):
        """Load and display company logo"""
        try:
            logo_image = Image.open("./utils/_logo_.png")
            ctk_logo = ctk.CTkImage(
                light_image=logo_image,
                dark_image=logo_image,
                size=(220, 40)
            )
            
            self.allianz_logo = ctk.CTkLabel(
                self.header_content,
                image=ctk_logo,
                text=""
            )
            self.allianz_logo.place(relx=1.0, rely=0.5, anchor="e", x=-20, y=0)
        except Exception as e:
            print(f"Error loading logo: {e}")

    def create_status_label(self):
        """Create status message display"""
        self.status_label = ctk.CTkLabel(
            self.main_container,
            text="",
            text_color="yellow"
        )
        self.status_label.pack(fill="x", padx=5)

    def create_notebook(self):
        """Create notebook for tabs"""
        self.notebook = ttk.Notebook(self.main_container)
        self.notebook.pack(fill="both", expand=True, padx=5, pady=5)
        self.notebook.bind('<<NotebookTabChanged>>', self.on_tab_changed)

    def setup_tabs(self):
        """Setup all tabs"""
        self.tabs = {
            'Data Centre': DataCentreTab(self.notebook, self.data_processor),
            'Performance': PerformanceTab(self.notebook, self.data_processor),
            'Claim': ClaimTab(self.notebook, self.data_processor),
            'Correlation': CorrelationTab(self.notebook, self.data_processor)
        }

        for name, tab in self.tabs.items():
            self.notebook.add(tab, text=name)

    def on_tab_changed(self, event):
        """Handle tab change events"""
        try:
            current_tab = self.notebook.select()
            tab_name = self.notebook.tab(current_tab, "text")
            self.current_tab = tab_name
            
            if self.data_processor.has_data():
                print(f"Tab changed to: {tab_name}")

        except Exception as e:
            self.show_error("Error updating tab visualizations", e)

    def show_error(self, message, error):
        """Display error message"""
        error_msg = f"{message}: {str(error)}"
        self.status_label.configure(text=error_msg)
        messagebox.showerror("Error", error_msg)
        print(f"Error: {error_msg}")
        print(traceback.format_exc())

if __name__ == "__main__":
    try:
        app = GeneralPricingSystem()
        app.mainloop()
    except Exception as e:
        print(f"Application error: {str(e)}")
        print(traceback.format_exc())

# gui/tabs/base_tab.py
import customtkinter as ctk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
from utils.plot_utils import PlotUtils
import tkinter as tk
from tkinter import ttk
import pandas as pd

class BaseTab(ctk.CTkFrame):
    def __init__(self, parent, data_processor):
        super().__init__(parent)
        self.data_processor = data_processor
        self.graphs = {}
        self.setup_ui()

    def setup_ui(self):
        """Setup UI components - to be implemented by child classes"""
        raise NotImplementedError

    def create_graph_frame(self, parent, title, row, column, columnspan=1):
        """Create a frame for matplotlib graph"""
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=column, sticky="nsew", padx=5, pady=5, columnspan=columnspan)

        # Title
        title_label = ctk.CTkLabel(
            frame,
            text=title,
            font=("Helvetica", 16, "bold")
        )
        title_label.pack(pady=5)

        # matplotlib graph
        fig = Figure(figsize=(8, 6), dpi=100)
        PlotUtils.setup_figure(fig)
        
        ax = fig.add_subplot(111)
        PlotUtils.setup_dark_style(ax)
            
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True, padx=5, pady=5)

        return {"frame": frame, "fig": fig, "ax": ax, "canvas": canvas}

    def update_view(self):
        """Update all visualizations - to be implemented by child classes"""
        raise NotImplementedError
    
    def update_table(self, section_id, data):
        """Update table with data"""
        if section_id not in self.sections:
            return
            
        tree = self.sections[section_id]["table"]
        
        # Clear existing data
        tree.delete(*tree.get_children())
        
        # Configure style for more readable view
        style = ttk.Style()
        style.configure("Compact.Treeview", 
                        rowheight=25,  # Slightly increased, but not too much
                        font=('Arial', 10))  # Slightly larger, but not bold
        style.configure("Compact.Treeview.Heading", 
                        font=('Arial', 10))  # Consistent heading font
        tree.configure(style="Compact.Treeview")
        
        # Reset columns
        tree["columns"] = ()
        tree.heading("#0", text="")
        tree.column("#0", width=0, stretch=tk.NO)
        
        if isinstance(data, pd.Series):
            # Convert series to dataframe
            data = data.reset_index()
            columns = data.columns.tolist()
        elif isinstance(data, pd.DataFrame):
            columns = data.columns.tolist()
        else:
            columns = ["Value"]
            data = pd.DataFrame({columns[0]: data})
        
        # Configure columns dynamically
        tree["columns"] = columns
        for col in columns:
            tree.heading(col, text=col)
            # More conservative width calculation
            col_width = max(
                len(col) * 10,  # Moderate header width
                max(len(str(val)) * 10 for val in data[col]) if not data[col].empty else 100,
                100  # Minimum width of 100 pixels
            )
            tree.column(col, width=col_width, anchor='center')
        
        # Add data rows
        for i, row in data.iterrows():
            # Convert all values to strings to avoid potential formatting issues
            values = [str(val) for val in row.tolist()]
            tree.insert("", "end", values=values)
        
        # Optional: Add scrollbar if many rows
        for child in tree.master.winfo_children():
            if isinstance(child, ttk.Scrollbar):
                child.destroy()
        
        scrollbar = ttk.Scrollbar(tree.master, orient="vertical", command=tree.yview)
        tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side="right", fill="y")

# gui/tabs/claim_tab.py
from .base_tab import BaseTab
import customtkinter as ctk
import tkinter as tk
from tkinter import ttk
import numpy as np
from utils.plot_utils import PlotUtils
import matplotlib.pyplot as plt
import pandas as pd

class ClaimTab(BaseTab):
    def setup_ui(self):
        """Setup Claim tab UI components with table + graph layout"""
        # Scrollable container
        self.scrollable_frame = ctk.CTkScrollableFrame(self)
        self.scrollable_frame.pack(fill="both", expand=True, padx=2, pady=2)

        # Create all visualization sections (table + graph pairs)
        self.create_visualization_sections()

    def create_visualization_sections(self):
        """Create all visualization sections with tables and graphs"""
        # Dictionary to store all UI elements
        self.sections = {}
        
        # Create sections for each visualization
        self.create_section("age", "Claims by Age Group")
        self.create_section("amount", "Claim Amount Distribution")
        self.create_section("diagnosis", "Claims by Diagnosis")
        self.create_section("monthly_trend", "Monthly Claim Trend")
        self.create_section("yearly_trend", "Yearly Claim Trend")
        self.create_section("avg_amount", "Average Claim by Age")
        self.create_section("gender", "Claims by Gender")
        self.create_section("seasonal", "Seasonal Pattern")

    def create_section(self, section_id, title):
        """Create a section with table (left) and graph (right)"""
        # Main section container
        section_frame = ctk.CTkFrame(self.scrollable_frame)
        section_frame.pack(fill="x", expand=True, padx=5, pady=10)
        
        # Title for the section
        title_label = ctk.CTkLabel(
            section_frame,
            text=title,
            font=("Helvetica", 16, "bold")
        )
        title_label.pack(pady=5)
        
        # Container for table and graph
        content_frame = ctk.CTkFrame(section_frame)
        content_frame.pack(fill="x", expand=True, padx=5, pady=5)
        content_frame.grid_columnconfigure(0, weight=1)
        content_frame.grid_columnconfigure(1, weight=1)
        
        # Create table (left side)
        table_frame = ctk.CTkFrame(content_frame)
        table_frame.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)
        
        # Create treeview for table
        tree_frame = ctk.CTkFrame(table_frame)
        tree_frame.pack(fill="both", expand=True, padx=5, pady=5)
        
        tree = ttk.Treeview(tree_frame)
        tree.pack(side="left", fill="both", expand=True)
        
        # Add scrollbar to table
        scrollbar = ttk.Scrollbar(tree_frame, orient="vertical", command=tree.yview)
        scrollbar.pack(side="right", fill="y")
        tree.configure(yscrollcommand=scrollbar.set)
        
        # Configure dark style for treeview
        style = ttk.Style()
        style.configure("Treeview", 
                        background="#2B2B2B",
                        foreground="white",
                        fieldbackground="#2B2B2B")
        style.map('Treeview', 
                 background=[('selected', '#347083')])
        
        # Create graph (right side)
        graph_dict = self.create_graph_frame(content_frame, "", row=0, column=1)
        
        # Store references to UI elements
        self.sections[section_id] = {
            "frame": section_frame,
            "table": tree,
            "graph": graph_dict
        }

    def update_view(self):
        """Update all claim visualizations"""
        # Debug message
        print("\n======== DEBUG: CLAIM TAB UPDATE_VIEW ========")
        print(f"Current active_data_type: {self.data_processor.active_data_type}")
        print(f"Claim data available: {self.data_processor.has_data('claim')}")
        
        if not self.data_processor.has_data('claim'):
            print("No claim data available to update Claim visualizations")
            print("======== DEBUG: CLAIM UPDATE SKIPPED ========\n")
            return

        try:
            # Always use claim data
            original_type = self.data_processor.active_data_type
            self.data_processor.active_data_type = 'claim'
            print(f"Set active_data_type to 'claim' (was {original_type})")
            
            print("Updating claim visualizations...")
            self.update_age_distribution()
            print("- Age distribution updated")
            self.update_amount_distribution()
            print("- Amount distribution updated")
            self.update_diagnosis_distribution()
            print("- Diagnosis distribution updated")
            self.update_monthly_trend()
            print("- Monthly trend updated")
            self.update_yearly_trend()
            print("- Yearly trend updated")
            self.update_average_amount()
            print("- Average amount updated")
            self.update_gender_distribution()
            print("- Gender distribution updated")
            self.update_seasonal_pattern()
            print("- Seasonal pattern updated")
            
            # Restore original data type
            self.data_processor.active_data_type = original_type
            print(f"Restored active_data_type to '{original_type}'")
            print("======== DEBUG: CLAIM UPDATE COMPLETE ========\n")
            
        except Exception as e:
            print(f"Error updating Claim visualizations: {str(e)}")
            import traceback
            print(traceback.format_exc())
            print("======== DEBUG: CLAIM UPDATE FAILED ========\n")
            raise e

    # def update_table(self, section_id, data):
    #     """Update table with data"""
    #     if section_id not in self.sections:
    #         return
            
    #     tree = self.sections[section_id]["table"]
        
    #     # Clear existing data
    #     tree.delete(*tree.get_children())
        
    #     # Reset columns
    #     for col in tree["columns"]:
    #         tree.heading(col, text="")
        
    #     if isinstance(data, pd.Series):
    #         # Convert series to dataframe
    #         data = data.reset_index()
    #         columns = data.columns.tolist()
            
    #         # Configure columns
    #         tree["columns"] = columns
    #         for col in columns:
    #             tree.heading(col, text=col)
            
    #         # Add data rows
    #         for i, row in data.iterrows():
    #             values = row.tolist()
    #             tree.insert("", "end", values=values)
                
    #     elif isinstance(data, pd.DataFrame):
    #         columns = data.columns.tolist()
            
    #         # Configure columns
    #         tree["columns"] = columns
    #         for col in columns:
    #             tree.heading(col, text=col)
            
    #         # Add data rows
    #         for i, row in data.iterrows():
    #             values = row.tolist()
    #             tree.insert("", "end", values=values)
                
    #     elif isinstance(data, np.ndarray):
    #         # For numpy arrays, create simple index
    #         tree["columns"] = ["Value"]
    #         tree.heading("Value", text="Value")
            
    #         for i, value in enumerate(data):
    #             tree.insert("", "end", values=[value])

    def update_age_distribution(self):
        """Update age distribution graph and table"""
        section_id = "age"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        age_dist = self.data_processor.get_age_distribution()
        if age_dist is not None:
            # Update table
            self.update_table(section_id, age_dist)
            
            # Update graph
            ax.bar(range(len(age_dist)), age_dist.values, color='skyblue')
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Number of Claims')
            ax.set_xticks(range(len(age_dist)))
            ax.set_xticklabels(age_dist.index, rotation=45)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_amount_distribution(self):
        """Update amount distribution graph and table"""
        section_id = "amount"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        amount_data = self.data_processor.get_amount_distribution()
        if amount_data is not None:
            # Create a histogram and get bin data for the table
            counts, bins = np.histogram(amount_data, bins=50)
            bin_centers = 0.5 * (bins[:-1] + bins[1:])
            hist_data = pd.DataFrame({
                'Bin_Start': bins[:-1],
                'Bin_End': bins[1:],
                'Count': counts
            })
            
            # Update table
            self.update_table(section_id, hist_data)
            
            # Update graph
            ax.hist(amount_data, bins=50, color='lightgreen')
            ax.set_xlabel('Claim Amount')
            ax.set_ylabel('Frequency')
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_diagnosis_distribution(self):
        """Update diagnosis distribution graph and table"""
        section_id = "diagnosis"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        diagnosis_data = self.data_processor.get_diagnosis_distribution()
        if diagnosis_data is not None:
            # Update table
            self.update_table(section_id, diagnosis_data)
            
            # Update graph
            ax.barh(range(len(diagnosis_data)), diagnosis_data.values, color='salmon')
            ax.set_xlabel('Number of Claims')
            ax.set_ylabel('Diagnosis')
            ax.set_yticks(range(len(diagnosis_data)))
            ax.set_yticklabels(diagnosis_data.index)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_monthly_trend(self):
        """Update monthly trend graph and table"""
        section_id = "monthly_trend"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        monthly_data = self.data_processor.get_monthly_trend()
        if monthly_data is not None:
            # Update table
            self.update_table(section_id, monthly_data)
            
            # Update graph
            ax.plot(range(len(monthly_data)), monthly_data.values, marker='o')
            ax.set_xlabel('Month')
            ax.set_ylabel('Number of Claims')
            ax.set_xticks(range(len(monthly_data)))
            ax.set_xticklabels([str(p) for p in monthly_data.index], rotation=45)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_yearly_trend(self):
        """Update yearly trend graph and table"""
        section_id = "yearly_trend"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        yearly_data = self.data_processor.get_yearly_trend()
        if yearly_data is not None:
            # Update table
            self.update_table(section_id, yearly_data)
            
            # Update graph
            ax1 = ax
            ax2 = ax1.twinx()
            
            x = range(len(yearly_data.index))
            bars = ax1.bar(x, yearly_data[('amount', 'count')],
                         color='lightblue', alpha=0.7)
            line = ax2.plot(x, yearly_data[('amount', 'mean')],
                          color='lightgreen', marker='o', linewidth=2)
            
            ax1.set_xlabel('Year')
            ax1.set_ylabel('Number of Claims', color='lightblue')
            ax2.set_ylabel('Average Claim Amount', color='lightgreen')
            
            ax1.set_xticks(x)
            ax1.set_xticklabels(yearly_data.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height):,}',
                        ha='center', va='bottom', color='white')
                
        PlotUtils.setup_dark_style(ax)
        PlotUtils.setup_dark_style(ax2)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_average_amount(self):
        """Update average amount by age graph and table"""
        section_id = "avg_amount"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        avg_by_age = self.data_processor.get_average_amount_by_age()
        if avg_by_age is not None:
            # Update table
            self.update_table(section_id, avg_by_age)
            
            # Update graph
            x = range(len(avg_by_age))
            bars = ax.bar(x, avg_by_age.values, color='lightblue')
            
            ax.set_xticks(x)
            ax.set_xticklabels(avg_by_age.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'${height:,.0f}',
                       ha='center', va='bottom', color='white')
                
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Average Claim Amount ($)')
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_gender_distribution(self):
        """Update gender distribution graph and table"""
        section_id = "gender"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        gender_data = self.data_processor.get_gender_distribution()
        if gender_data is not None:
            # Update table
            self.update_table(section_id, gender_data)
            
            # Group data by age_group
            age_groups = gender_data['age_group'].unique()
            n_groups = len(age_groups)
            
            bar_width = 0.35
            index = np.arange(n_groups)
            
            # Get data for males and females
            male_data = gender_data[gender_data['gender'] == 'M']['count'].values
            female_data = gender_data[gender_data['gender'] == 'F']['count'].values
            
            # Create bars
            ax.bar(index - bar_width/2, male_data, bar_width, 
                  label='Male', color='lightblue')
            ax.bar(index + bar_width/2, female_data, bar_width,
                  label='Female', color='lightpink')
            
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Number of Claims')
            ax.set_xticks(index)
            ax.set_xticklabels(age_groups, rotation=45)
            ax.legend()
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_seasonal_pattern(self):
        """Update seasonal pattern graph and table"""
        section_id = "seasonal"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        seasonal_data = self.data_processor.get_seasonal_pattern()
        if seasonal_data is not None:
            # Update table
            self.update_table(section_id, seasonal_data)
            
            ax1 = ax
            ax2 = ax1.twinx()
            
            x = range(len(seasonal_data.index))
            bars = ax1.bar(x, seasonal_data[('amount', 'count')],
                         color='lightblue', alpha=0.7)
            line = ax2.plot(x, seasonal_data[('amount', 'mean')],
                          color='lightgreen', marker='o', linewidth=2)
            
            ax1.set_xlabel('Season')
            ax1.set_ylabel('Number of Claims', color='lightblue')
            ax2.set_ylabel('Average Claim Amount', color='lightgreen')
            
            ax1.set_xticks(x)
            ax1.set_xticklabels(seasonal_data.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height):,}',
                        ha='center', va='bottom', color='white')
                
        PlotUtils.setup_dark_style(ax)
        PlotUtils.setup_dark_style(ax2)
        self.sections[section_id]["graph"]["canvas"].draw()

# gui/tabs/correlation_tab.py
from .base_tab import BaseTab
import customtkinter as ctk
import numpy as np
import seaborn as sns
from utils.plot_utils import PlotUtils
import matplotlib.pyplot as plt
import pandas as pd  # 이 줄을 추가하세요

class CorrelationTab(BaseTab):
    def setup_ui(self):
        """Setup Correlation tab UI components"""
        # Create scrollable frame
        self.scrollable_frame = ctk.CTkScrollableFrame(self)
        self.scrollable_frame.pack(fill="both", expand=True, padx=5, pady=5)

        # Correlation visualization frames
        self.correlation_frames = ctk.CTkFrame(self.scrollable_frame)
        self.correlation_frames.pack(fill="both", expand=True, padx=5, pady=5)

        # Create graph frames
        self.create_graph_frames()
        self.configure_grid()

    def create_graph_frames(self):
        """Create all graph frames for correlation analysis"""
        self.graphs = {
            'heatmap': self.create_graph_frame(
                self.correlation_frames,
                "Correlation Heatmap",
                row=0, column=0, columnspan=2
            ),
            'pairs': self.create_graph_frame(
                self.correlation_frames,
                "Pairwise Relationships",
                row=1, column=0, columnspan=2
            ),
            'top_correlations': self.create_graph_frame(
                self.correlation_frames,
                "Top 10 Correlations",
                row=2, column=0
            ),
            'scatter': self.create_graph_frame(
                self.correlation_frames,
                "Key Variables vs Claims",
                row=2, column=1
            )
        }

    def configure_grid(self):
        """Configure grid layout"""
        self.correlation_frames.grid_columnconfigure(0, weight=1)
        self.correlation_frames.grid_columnconfigure(1, weight=1)
        for i in range(3):
            self.correlation_frames.grid_rowconfigure(i, weight=1)

    def update_view(self):
        """Update all correlation visualizations"""
        if not self.data_processor.has_data():
            return

        self.update_correlation_heatmap()
        self.update_pairwise_relationships()
        self.update_top_correlations()
        self.update_key_variables_scatter()

    def update_correlation_heatmap(self):
        """Update correlation heatmap"""
        ax = self.graphs['heatmap']['ax']
        ax.clear()
        fig = self.graphs['heatmap']['fig']
        
        corr_matrix = self.data_processor.get_correlation_matrix()
        if corr_matrix is not None:
            fig.subplots_adjust(left=0.15, right=0.95, bottom=0.2, top=0.9)
            
            sns.heatmap(corr_matrix, 
                       annot=True, 
                       cmap='coolwarm', 
                       ax=ax,
                       fmt='.2f',
                       annot_kws={'size': 8},
                       mask=np.triu(np.ones_like(corr_matrix, dtype=bool)))
            
            ax.set_title('Correlation Heatmap', color='white', pad=20)
            plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
            plt.setp(ax.get_yticklabels(), rotation=0)
            
        PlotUtils.setup_dark_style(ax)
        self.graphs['heatmap']['canvas'].draw()

    def update_pairwise_relationships(self):
        """Update pairwise relationships visualization"""
        ax = self.graphs['pairs']['ax']
        ax.clear()
        fig = self.graphs['pairs']['fig']
        
        if self.data_processor.has_data():
            fig.subplots_adjust(left=0.1, right=0.95, bottom=0.2, top=0.9)
            
            # Use correlation matrix to get top categorical features
            corr_matrix = self.data_processor.get_correlation_matrix()
            
            # Get top features based on their correlation to each other
            correlation_values = corr_matrix.abs().sum()
            top_features = correlation_values.sort_values(ascending=False)[:4].index
            
            data = self.data_processor.get_data()
            n_features = len(top_features)
            
            for i in range(n_features):
                for j in range(n_features):
                    plt_ax = ax.inset_axes([0.25*i, 0.25*j, 0.23, 0.23])
                    
                    # If not on diagonal, create scatter/bar plot
                    if i != j:
                        # For categorical variables, create stacked bar plot
                        crosstab = pd.crosstab(data[top_features[i]], data[top_features[j]])
                        crosstab.plot(kind='bar', stacked=True, ax=plt_ax, legend=False)
                        plt_ax.set_xlabel('')
                        plt_ax.set_ylabel('')
                    else:
                        # On diagonal, show distribution
                        data[top_features[i]].value_counts().plot(kind='bar', ax=plt_ax)
                        plt_ax.set_title('')

                    if i == 0:
                        plt_ax.set_ylabel(top_features[j], color='white')
                    if j == n_features-1:
                        plt_ax.set_xlabel(top_features[i], color='white')
                    plt_ax.tick_params(colors='white', labelsize=8, rotation=45)
            
            ax.set_title('Pairwise Relationships of Top Categorical Features', color='white', pad=20)
            
        PlotUtils.setup_dark_style(ax)
        self.graphs['pairs']['canvas'].draw()

    def update_top_correlations(self):
        """Update top correlations visualization"""
        ax = self.graphs['top_correlations']['ax']
        ax.clear()
        fig = self.graphs['top_correlations']['fig']
        
        if self.data_processor.has_data():
            fig.subplots_adjust(left=0.3, right=0.95, bottom=0.2, top=0.9)
            
            corr_matrix = self.data_processor.get_correlation_matrix()
            
            # Calculate overall correlation and sort
            correlation_values = corr_matrix.abs().sum()
            top_corr = correlation_values.sort_values(ascending=True)
            top_corr = top_corr.drop(top_corr.index[top_corr.index == top_corr.index[0]])
            
            colors = ['red' if x < 0 else 'green' for x in top_corr]
            bars = ax.barh(range(len(top_corr)), top_corr, color=colors)
            ax.set_yticks(range(len(top_corr)))
            ax.set_yticklabels(top_corr.index, fontsize=8)
            ax.set_xlabel('Correlation Coefficient')
            ax.set_title('Correlations between Categorical Variables', pad=20)
            
            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax.text(width, i, f'{width:.2f}', 
                    color='white', 
                    va='center',
                    ha='left' if width >= 0 else 'right')
            
        PlotUtils.setup_dark_style(ax)
        self.graphs['top_correlations']['canvas'].draw()

    def update_key_variables_scatter(self):
        """Update key variables scatter plots"""
        ax = self.graphs['scatter']['ax']
        ax.clear()
        fig = self.graphs['scatter']['fig']
        
        if self.data_processor.has_data():
            fig.subplots_adjust(left=0.15, right=0.95, bottom=0.2, top=0.9)
            
            corr_matrix = self.data_processor.get_correlation_matrix()
            
            # Get top features based on overall correlation
            correlation_values = corr_matrix.abs().sum()
            top_vars = correlation_values.sort_values(ascending=False)[1:4].index
            
            # For categorical variables, use stacked bar plot
            data = self.data_processor.get_data()
            
            colors = plt.cm.tab10(np.linspace(0, 1, len(top_vars)))
            for var, color in zip(top_vars, colors):
                # Create a cross-tabulation for the variables
                crosstab = pd.crosstab(data[var], columns='count', normalize='index')
                crosstab.plot(kind='bar', color=color, ax=ax, label=var)
            
            ax.set_xlabel('Categories')
            ax.set_ylabel('Proportion')
            ax.legend()
            ax.set_title('Distribution of Top Categorical Variables', pad=20)
            
        PlotUtils.setup_dark_style(ax)
        self.graphs['scatter']['canvas'].draw()

# gui/tabs/data_centre_tab.py
from gui.tabs.base_tab import BaseTab
import customtkinter as ctk
import tkinter as tk
from tkinter import filedialog, messagebox
from datetime import datetime
from pathlib import Path
import shutil
import os
import pandas as pd

class DataCentreTab(BaseTab):
    def setup_ui(self):
        """Setup Data Centre tab UI components based on the new design"""
        # Create main scrollable frame
        self.main_scrollable = ctk.CTkScrollableFrame(self)
        self.main_scrollable.pack(fill="both", expand=True)
        
        # Section 1: Data Loading
        self.create_data_loading_section()
        
        # Section 2: Data Filtering
        self.create_data_filtering_section()
        
        # Section 3: Control
        self.create_control_section()
        
        # Initialize selection tracking variables
        self.selected_database = None  # 'standard' or 'claim'
        self.selected_dataset = None
        
        # IMPORTANT: DO NOT DISABLE FILTERING CONTROLS AT ALL
        # Remove any calls to enable_filter_controls() here
        
    def create_section_label(self, parent, text):
        """Create section label"""
        frame = ctk.CTkFrame(parent)
        frame.pack(fill="x", padx=10, pady=(10, 5))
        
        label = ctk.CTkLabel(
            frame,
            text=text,
            font=("Helvetica", 16, "bold")
        )
        label.pack(anchor="w", padx=10, pady=5)
        
        return frame
    
    def create_data_loading_section(self):
        """Create data loading section (Section 1)"""
        # Main section label
        data_loading_frame = self.create_section_label(self.main_scrollable, "Data Loading")
        
        # Settings section (1-1)
        self.create_settings_section(data_loading_frame)
        
        # Databases section
        self.create_databases_section(data_loading_frame)
        
    def create_settings_section(self, parent):
        """Create settings section with username and password (1-1)"""
        settings_frame = ctk.CTkFrame(parent)
        settings_frame.pack(fill="x", padx=10, pady=5)
        
        # Settings label (1-1)
        settings_label = ctk.CTkLabel(
            settings_frame,
            text="Settings",
            font=("Helvetica", 14, "bold")
        )
        settings_label.pack(anchor="w", padx=10, pady=5)
        
        # Credentials frame
        credentials_frame = ctk.CTkFrame(settings_frame)
        credentials_frame.pack(fill="x", padx=10, pady=5)
        
        # Username (1-1-1)
        username_label = ctk.CTkLabel(
            credentials_frame,
            text="Username:"
        )
        username_label.pack(side="left", padx=(10, 5))
        
        self.username_entry = ctk.CTkEntry(
            credentials_frame,
            placeholder_text="Enter your PLSQL username",
            width=200
        )
        self.username_entry.pack(side="left", padx=5)
        
        # Password (1-1-2)
        password_label = ctk.CTkLabel(
            credentials_frame,
            text="Password:"
        )
        password_label.pack(side="left", padx=(20, 5))
        
        self.password_entry = ctk.CTkEntry(
            credentials_frame,
            placeholder_text="Enter your PLSQL password",
            width=200,
            show="*"  # Show asterisks for password
        )
        self.password_entry.pack(side="left", padx=5)
        
        # Confirm button (1-1-4)
        self.confirm_credentials_btn = ctk.CTkButton(
            credentials_frame,
            text="Confirm",
            command=self.save_credentials,
            width=100
        )
        self.confirm_credentials_btn.pack(side="left", padx=10)
        
        # Status message (1-1-3)
        self.credentials_status = ctk.CTkLabel(
            credentials_frame,
            text="",
            text_color="yellow"
        )
        self.credentials_status.pack(side="right", padx=10, fill="x", expand=True)
    
    def create_databases_section(self, parent):
        """Create standard and claim database sections (1-2, 1-3)"""
        # Container for both database sections
        databases_frame = ctk.CTkFrame(parent)
        databases_frame.pack(fill="x", padx=10, pady=5)
        
        # Configure grid for databases frame
        databases_frame.grid_columnconfigure(0, weight=1)
        databases_frame.grid_columnconfigure(1, weight=1)
        
        # Create Standard database section (1-2)
        self.create_database_panel(
            databases_frame, 
            "Standard", 
            row=0, 
            column=0, 
            prefix="standard"
        )
        
        # Create Claim database section (1-3)
        self.create_database_panel(
            databases_frame, 
            "Claim", 
            row=0, 
            column=1, 
            prefix="claim"
        )
    
    def create_database_panel(self, parent, title, row, column, prefix):
        """Create a database panel with listbox and controls"""
        # Main frame
        panel_frame = ctk.CTkFrame(parent)
        panel_frame.grid(row=row, column=column, padx=5, pady=5, sticky="nsew")
        
        # Title
        panel_title = ctk.CTkLabel(
            panel_frame,
            text=title,
            font=("Helvetica", 14, "bold")
        )
        panel_title.pack(anchor="w", padx=10, pady=5)
        
        # Listbox frame
        listbox_frame = ctk.CTkFrame(panel_frame)
        listbox_frame.pack(fill="both", expand=True, padx=10, pady=5)
        
        # Create listbox with scrollbar
        listbox = tk.Listbox(
            listbox_frame,
            bg='#2B2B2B',
            fg='white',
            selectmode=tk.SINGLE,
            height=8
        )
        listbox.pack(side="left", fill="both", expand=True)
        
        scrollbar = tk.Scrollbar(listbox_frame, orient="vertical")
        scrollbar.pack(side="right", fill="y")
        
        listbox.config(yscrollcommand=scrollbar.set)
        scrollbar.config(command=listbox.yview)
        
        # Set a selection event handler
        listbox.bind('<<ListboxSelect>>', 
                    lambda event, p=prefix: self.on_database_select(event, p))
        
        # Store reference to listbox
        setattr(self, f"{prefix}_listbox", listbox)
        
        # Populate listbox with database tables
        try:
            tables = self.data_processor.get_table_list(prefix)
            for table in tables:
                listbox.insert(tk.END, f"{table['display_name']} - {table['date']} - By {table.get('username', 'Unknown')}")
        except Exception as e:
            print(f"Error loading databases: {e}")
        
        # Database query section
        query_frame = ctk.CTkFrame(panel_frame)
        query_frame.pack(fill="x", padx=10, pady=5)
        
        db_entry = ctk.CTkEntry(
            query_frame,
            placeholder_text="Enter dataset name"
        )
        db_entry.pack(side="left", fill="x", expand=True, padx=(0, 5))
        
        db_btn = ctk.CTkButton(
            query_frame,
            text="From Database",
            command=lambda p=prefix, e=db_entry: self.query_database(p, e),
            width=120
        )
        db_btn.pack(side="right")
        
        # Store reference
        setattr(self, f"{prefix}_db_entry", db_entry)
        
        # File upload section
        file_frame = ctk.CTkFrame(panel_frame)
        file_frame.pack(fill="x", padx=10, pady=5)
        
        file_entry = ctk.CTkEntry(
            file_frame,
            placeholder_text="Enter dataset name"
        )
        file_entry.pack(side="left", fill="x", expand=True, padx=(0, 5))
        
        file_btn = ctk.CTkButton(
            file_frame,
            text="From File",
            command=lambda p=prefix, e=file_entry: self.upload_file(p, e),
            width=120
        )
        file_btn.pack(side="right")
        
        # Store reference
        setattr(self, f"{prefix}_file_entry", file_entry)
        
        # Button container
        button_frame = ctk.CTkFrame(panel_frame)
        button_frame.pack(fill="x", padx=10, pady=5)
        
        # Configure button container columns
        button_frame.grid_columnconfigure(0, weight=1)
        button_frame.grid_columnconfigure(1, weight=1)
        
        # Confirm button
        confirm_btn = ctk.CTkButton(
            button_frame,
            text="Confirm Dataset",
            command=lambda p=prefix: self.confirm_database_selection(p),
            height=30
        )
        confirm_btn.grid(row=0, column=0, padx=(0, 5), pady=5, sticky="ew")
        
        # Delete button
        delete_btn = ctk.CTkButton(
            button_frame,
            text="Delete Dataset",
            command=lambda p=prefix: self.delete_database_selection(p),
            height=30,
            fg_color="#E74C3C",
            hover_color="#C0392B"
        )
        delete_btn.grid(row=0, column=1, padx=(5, 0), pady=5, sticky="ew")
        
        # Status message
        status_frame = ctk.CTkFrame(panel_frame)
        status_frame.pack(fill="x", padx=10, pady=(0, 10))
        
        status_label = ctk.CTkLabel(
            status_frame,
            text="",
            text_color="yellow",
            height=20
        )
        status_label.pack(fill="x", padx=10, pady=2)
        
        # Store references
        setattr(self, f"{prefix}_status", status_label)
        setattr(self, f"{prefix}_confirm_btn", confirm_btn)
        setattr(self, f"{prefix}_delete_btn", delete_btn)
    
    def create_data_filtering_section(self):
        """Create data filtering section (Section 2)"""
        # Main section label
        data_filtering_frame = self.create_section_label(self.main_scrollable, "Data Filtering")
        
        # First row for filter buttons
        row1_frame = ctk.CTkFrame(data_filtering_frame)
        row1_frame.pack(fill="x", padx=5, pady=5)
        row1_frame.grid_columnconfigure(0, weight=1)
        row1_frame.grid_columnconfigure(1, weight=1)
        
        # Grouping filter
        grouping_label = ctk.CTkLabel(row1_frame, text="Grouping:")
        grouping_label.grid(row=0, column=0, padx=(10, 5), pady=5, sticky="w")
        
        self.grouping_btn = ctk.CTkButton(
            row1_frame,
            text="Select grouping",
            command=lambda: self.open_filter_selection("Grouping"),
            width=200
        )
        self.grouping_btn.grid(row=0, column=0, padx=(100, 10), pady=5, sticky="ew")
        
        # Country filter
        country_label = ctk.CTkLabel(row1_frame, text="Country:")
        country_label.grid(row=0, column=1, padx=(10, 5), pady=5, sticky="w")
        
        self.country_btn = ctk.CTkButton(
            row1_frame,
            text="Select countries",
            command=lambda: self.open_filter_selection("Country"),
            width=200
        )
        self.country_btn.grid(row=0, column=1, padx=(100, 10), pady=5, sticky="ew")
        
        # Second row for filter buttons
        row2_frame = ctk.CTkFrame(data_filtering_frame)
        row2_frame.pack(fill="x", padx=5, pady=5)
        row2_frame.grid_columnconfigure(0, weight=1)
        row2_frame.grid_columnconfigure(1, weight=1)
        
        # Continent filter
        continent_label = ctk.CTkLabel(row2_frame, text="Continent:")
        continent_label.grid(row=0, column=0, padx=(10, 5), pady=5, sticky="w")
        
        self.continent_btn = ctk.CTkButton(
            row2_frame,
            text="Select continents",
            command=lambda: self.open_filter_selection("Continent"),
            width=200
        )
        self.continent_btn.grid(row=0, column=0, padx=(100, 10), pady=5, sticky="ew")
        
        # Rating Year filter
        rating_year_label = ctk.CTkLabel(row2_frame, text="Rating Year:")
        rating_year_label.grid(row=0, column=1, padx=(10, 5), pady=5, sticky="w")
        
        self.rating_year_btn = ctk.CTkButton(
            row2_frame,
            text="Select rating years",
            command=lambda: self.open_filter_selection("Rating Year"),
            width=200
        )
        self.rating_year_btn.grid(row=0, column=1, padx=(100, 10), pady=5, sticky="ew")
        
        # Apply and Reset Filters buttons - DIRECTLY in data_filtering_frame
        self.apply_filter_btn = ctk.CTkButton(
            data_filtering_frame,
            text="Apply Filters",
            command=self.apply_filters,
            width=150
        )
        self.apply_filter_btn.pack(side="left", padx=(10, 5), pady=10)
        
        self.reset_filter_btn = ctk.CTkButton(
            data_filtering_frame,
            text="Reset Filters",
            command=self.reset_filters,
            width=150
        )
        self.reset_filter_btn.pack(side="left", padx=5, pady=10)
        
        # Filter status message
        self.filter_status = ctk.CTkLabel(
            data_filtering_frame,
            text="",
            text_color="yellow",
            wraplength=800
        )
        self.filter_status.pack(side="left", padx=10, fill="x", expand=True)
        
        # Initialize selected filter values
        self.grouping_selected = set()
        self.country_selected = set()
        self.continent_selected = set()
        self.rating_year_selected = set()
    
    def create_control_section(self):
        """Create control section (Section 3)"""
        # Main section label
        control_frame = self.create_section_label(self.main_scrollable, "Control")
        
        # Update Tables/Graphs button (3-1)
        self.update_btn = ctk.CTkButton(
            control_frame,
            text="Update Tables/Graphs",
            command=self.update_visualizations,
            width=200,
            height=30
        )
        self.update_btn.pack(side="left", padx=10, pady=10)
        
        # Download in Excel button (3-2)
        self.excel_btn = ctk.CTkButton(
            control_frame,
            text="Download in Excel",
            command=self.download_excel,
            width=200,
            height=30
        )
        self.excel_btn.pack(side="left", padx=10, pady=10)
        
        # Status message (3-3) - 컨테이너 제거, 직접 control_frame에 배치
        self.control_status = ctk.CTkLabel(
            control_frame,
            text="",
            text_color="yellow"
        )
        self.control_status.pack(side="left", padx=10, fill="x", expand=True)
    
    def delete_database_selection(self, prefix):
        """Delete selected dataset from database (handler for delete button)"""
        listbox = getattr(self, f"{prefix}_listbox")
        status_label = getattr(self, f"{prefix}_status")
        
        selection = listbox.curselection()
        if not selection:
            status_label.configure(text="Please select a dataset first")
            return
        
        selected_item = listbox.get(selection[0])
        parts = selected_item.split(" - ")
        dataset_name = parts[0]
        
        # Confirm with user before deletion
        confirm = messagebox.askyesno(
            "Confirm Deletion",
            f"Are you sure you want to delete the dataset '{dataset_name}'?",
            icon="warning"
        )
        
        if not confirm:
            return
        
        try:
            # Call the data processor's delete method
            success, error = self.data_processor.delete_from_database(prefix, dataset_name)
            
            if success:
                # Remove item from listbox
                listbox.delete(selection[0])
                
                # Update status label
                status_label.configure(text=f"Successfully deleted dataset '{dataset_name}'")
                
                # If this was the currently selected dataset, clear it
                if (hasattr(self, "selected_dataset") and 
                    hasattr(self, "selected_database") and
                    self.selected_dataset == dataset_name and
                    self.selected_database == prefix):
                    self.selected_dataset = None
                    self.selected_database = None
            else:
                status_label.configure(text=f"Deletion error: {error}")
                    
        except Exception as e:
            status_label.configure(text=f"Dataset deletion error: {str(e)}")

    # ============== Event Handlers ==============
    
    def save_credentials(self):
        """Handle the credentials confirmation button (1-1-4)"""
        username = self.username_entry.get()
        password = self.password_entry.get()
        
        if not username or not password:
            self.credentials_status.configure(text="Please enter both username and password")
            return
        
        # Here you would save or validate the credentials
        # For now, we'll just show a success message
        self.credentials_status.configure(text="Credentials saved successfully")
        
        # In a real application, you might store these for database access
        self.db_username = username
        self.db_password = password
    
    def on_database_select(self, event, prefix):
        """Handle database selection in listbox (1-2-1, 1-3-1)"""
        listbox = getattr(self, f"{prefix}_listbox")
        selection = listbox.curselection()
        
        if selection:
            # Enable the confirm button
            confirm_btn = getattr(self, f"{prefix}_confirm_btn")
            confirm_btn.configure(state="normal")
            
            # Clear selection in the other listbox
            other_prefix = "claim" if prefix == "standard" else "standard"
            other_listbox = getattr(self, f"{other_prefix}_listbox")
            other_listbox.selection_clear(0, tk.END)
            
            # Store selection information
            selected_item = listbox.get(selection[0])
            self.selected_database = prefix
            self.selected_dataset = selected_item
            
            # Set appropriate status message based on data type
            if prefix == 'claim':
                self.filter_status.configure(text="Filtering is only available for Standard data")
            else:
                self.filter_status.configure(text="")
    
    def query_database(self, prefix, entry):
        """Handle database query processing (1-2-3, 1-3-3)"""
        db_name = entry.get()
        status_label = getattr(self, f"{prefix}_status")
        
        if not db_name:
            status_label.configure(text="Please enter a database name")
            return
            
        try:
            # Search from table list
            tables = self.data_processor.get_table_list(prefix)
            matching_tables = [t for t in tables if db_name.lower() in t['display_name'].lower()]
            
            listbox = getattr(self, f"{prefix}_listbox")
            listbox.delete(0, tk.END)
            
            for table in matching_tables:
                listbox.insert(tk.END, f"{table['display_name']} - {table['date']} - {table['rows']} rows")
            
            if matching_tables:
                status_label.configure(text=f"Found {len(matching_tables)} matching datasets")
            else:
                status_label.configure(text=f"No datasets matching '{db_name}'")
                
        except Exception as e:
            status_label.configure(text=f"Query error: {str(e)}")

    def upload_file(self, prefix, entry):
        """Handle file upload processing (1-2-5, 1-3-5)"""
        file_nickname = entry.get()
        status_label = getattr(self, f"{prefix}_status")
        
        if not file_nickname:
            status_label.configure(text="Please enter a dataset name")
            return
        
        try:
            # File selection dialog
            file_path = filedialog.askopenfilename(
                title=f"Select {prefix.capitalize()} File",
                filetypes=[
                    ("CSV files", "*.csv"),
                    ("Excel files", "*.xlsx"),
                    ("Excel files (old)", "*.xls"),
                    ("All files", "*.*")
                ]
            )
            
            if not file_path:
                return  # User canceled
                
            # Check file extension
            path = Path(file_path)
            if path.suffix.lower() == '.csv':
                data = pd.read_csv(file_path)
            elif path.suffix.lower() in ['.xlsx', '.xls']:
                data = pd.read_excel(file_path)
            else:
                status_label.configure(text=f"Unsupported file format: {path.suffix}")
                return
                
            # Data validation
            self.data_processor.validate_data(data, prefix)
            
            # Get username - first check the current value in username entry
            username = self.username_entry.get().strip()
            
            # If username is empty, use a default or prompt for input
            if not username:
                # Option 1: Use system username
                import getpass
                username = getpass.getuser()
                
                # Option 2: Prompt user (uncomment if you prefer a dialog)
                # username = simpledialog.askstring("Username", "Enter your username:")
                # if not username:
                #     username = 'Unknown'
            
            # Save to database with username
            success, error = self.data_processor.save_to_database(
                data, 
                prefix, 
                file_nickname, 
                username
            )
            
            if success:
                # Update listbox
                listbox = getattr(self, f"{prefix}_listbox")
                current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
                listbox.insert(tk.END, f"{file_nickname} - {current_time} - By {username}")
                
                # Clear input field
                entry.delete(0, tk.END)
                
                status_label.configure(text=f"Successfully uploaded file '{file_nickname}'")
            else:
                status_label.configure(text=f"Save error: {error}")
                
        except Exception as e:
            status_label.configure(text=f"File upload error: {str(e)}")

    def confirm_database_selection(self, prefix):
        """Confirm database selection (1-2-7, 1-3-7)"""
        listbox = getattr(self, f"{prefix}_listbox")
        status_label = getattr(self, f"{prefix}_status")
        
        selection = listbox.curselection()
        if not selection:
            status_label.configure(text="Please select a dataset first")
            return
        
        selected_item = listbox.get(selection[0])
        parts = selected_item.split(" - ")
        dataset_name = parts[0]
        
        try:
            # Load data from database
            success, data, error = self.data_processor.load_from_database(prefix, dataset_name)
            
            if success:
                # Update status label
                status_label.configure(text=f"Successfully loaded dataset '{dataset_name}'")
                
                # Store selected dataset
                self.selected_database = prefix
                self.selected_dataset = dataset_name
                
                # Update filter section
                if prefix == 'standard':
                    self.update_filter_options()
                    self.filter_status.configure(text="")
                else:  # Claim data
                    self.filter_status.configure(text="Filtering is only available for Standard data")
                    
                # 이 부분을 제거하여 자동 업데이트를 방지합니다.
                # 아래 코드 삭제:
                # main_app = self.master.master.master
                # if prefix == 'standard':
                #     for tab_name, tab in main_app.tabs.items():
                #         if tab_name == 'Performance':
                #             tab.update_view()
                #             break
                # elif prefix == 'claim':
                #     for tab_name, tab in main_app.tabs.items():
                #         if tab_name == 'Claim':
                #             tab.update_view()
                #             break
                
                # 대신 상태 메시지를 업데이트하여 사용자에게 다음 단계를 안내합니다.
                self.control_status.configure(text="Dataset loaded. Please apply filters if needed, then click 'Update Tables/Graphs' to visualize.")
                
            else:
                status_label.configure(text=f"Data loading error: {error}")
                    
        except Exception as e:
            status_label.configure(text=f"Dataset loading error: {str(e)}")

    def enable_filter_controls(self, enable=True):
        """This method is no longer used to disable controls, only sets status message"""
        # This method now only sets status message without changing button states
        if not enable:
            self.filter_status.configure(text="Filtering is only available for Standard data")
        else:
            self.filter_status.configure(text="")
    
    def open_filter_selection(self, filter_name):
        """Open multi-select window for filters"""
        # Check if standard data is loaded
        if not hasattr(self.data_processor, 'standard_data') or self.data_processor.standard_data is None:
            messagebox.showinfo("Not Available", "Please load and confirm a standard dataset first.")
            self.filter_status.configure(text="Please load and confirm a standard dataset first")
            return
            
        # Get available options for the filter
        options = self.get_filter_options(filter_name)
        
        # If no options available, show message and return
        if not options:
            messagebox.showinfo("No Options", f"No {filter_name.lower()} options available in the loaded data.")
            self.filter_status.configure(text=f"No {filter_name.lower()} options available in the data")
            return
        
        # Create popup window
        popup = ctk.CTkToplevel(self)
        popup.title(f"Select {filter_name}")
        popup.geometry("400x500")
        
        # Get current selections
        attr_name = f"{filter_name.lower().replace(' ', '_')}_selected"
        current_selections = getattr(self, attr_name)
        
        # Create scrollable frame for options
        scroll_frame = ctk.CTkScrollableFrame(popup)
        scroll_frame.pack(fill="both", expand=True, padx=20, pady=(20, 0))
        
        # Dictionary to store checkboxes variables
        checkbox_vars = {}
        
        # Create checkbox for each option
        for option in options:
            var = tk.BooleanVar(value=option in current_selections)
            checkbox_vars[option] = var
            
            checkbox = ctk.CTkCheckBox(
                scroll_frame,
                text=str(option),
                variable=var,
                width=350
            )
            checkbox.pack(anchor="w", padx=10, pady=2)
        
        # Create buttons frame
        button_frame = ctk.CTkFrame(popup, height=60)
        button_frame.pack(fill="x", padx=20, pady=20, side="bottom")
        button_frame.pack_propagate(False)
        
        # Function to handle selection confirmation
        def confirm_selection():
            selected = {opt for opt, var in checkbox_vars.items() if var.get()}
            setattr(self, attr_name, selected)
            
            btn = getattr(self, f"{filter_name.lower().replace(' ', '_')}_btn")
            if selected:
                text = f"{len(selected)} item{'s' if len(selected) > 1 else ''} selected"
            else:
                text = f"Select {filter_name}"
            btn.configure(text=text)
            
            popup.destroy()
        
        # Function to handle selection cancellation
        def cancel_selection():
            popup.destroy()
        
        # Function to select all options
        def select_all():
            for var in checkbox_vars.values():
                var.set(True)
        
        # Function to clear all selections
        def clear_all():
            for var in checkbox_vars.values():
                var.set(False)
        
        # Create control buttons
        ctk.CTkButton(
            button_frame,
            text="Select All",
            command=select_all,
            width=80,
            height=30
        ).pack(side="left", padx=5, pady=10)
        
        ctk.CTkButton(
            button_frame,
            text="Clear All",
            command=clear_all,
            width=80,
            height=30
        ).pack(side="left", padx=5, pady=10)
        
        ctk.CTkButton(
            button_frame,
            text="Cancel",
            command=cancel_selection,
            width=80,
            height=30
        ).pack(side="right", padx=5, pady=10)
        
        ctk.CTkButton(
            button_frame,
            text="Confirm",
            command=confirm_selection,
            width=80,
            height=30,
            fg_color="#2B6AD0",
            hover_color="#1E4C9A"
        ).pack(side="right", padx=5, pady=10)
    
    def get_filter_options(self, filter_name):
        """Get available options for a specific filter"""
        # 디버깅을 위한 로그 추가
        print(f"Getting filter options for: {filter_name}")
        
        # 원본 데이터셋 사용
        data = self.data_processor.original_standard_data
        
        if data is None:
            print("No original standard data available")
            return []
        
        filter_column_map = {
            "Grouping": 'group',
            "Country": 'country',
            "Continent": 'continent',
            "Rating Year": 'rating_year'
        }
        
        column = filter_column_map.get(filter_name)
        
        if column and column in data.columns:
            # For rating year, convert to string to match existing code
            if column == 'rating_year':
                options = sorted(str(year) for year in data[column].unique())
            else:
                options = sorted(data[column].unique())
            
            print(f"Filter options for {filter_name}: {options}")
            return options
        
        print(f"No column found for {filter_name}")
        return []
    
    def update_filter_options(self):
        """Update available filter options based on loaded data"""
        if not hasattr(self.data_processor, 'standard_data') or self.data_processor.standard_data is None:
            return
        
        try:
            for filter_name in ['Grouping', 'Country', 'Continent', 'Rating Year']:
                # Get all possible options for this filter
                options = self.get_filter_options(filter_name)
                
                # Determine the attribute name for selected options
                attr_name = f"{filter_name.lower().replace(' ', '_')}_selected"
                btn_name = f"{filter_name.lower().replace(' ', '_')}_btn"
                
                # Get the current button and selected options
                btn = getattr(self, btn_name, None)
                
                # Get current selected options
                current_selected = getattr(self, attr_name, set())
                
                # Ensure all original options are preserved
                valid_selected = {opt for opt in current_selected if opt in options}
                
                # Update selected options to include all original options
                # but keep the current selections
                setattr(self, attr_name, valid_selected)
                
                # Update button text
                if btn:
                    if valid_selected:
                        btn.configure(text=f"{len(valid_selected)} items selected")
                    else:
                        btn.configure(text=f"Select {filter_name}")
            
            self.filter_status.configure(text="")
            
        except Exception as e:
            print(f"Error updating filter options: {str(e)}")
            self.filter_status.configure(text="Error updating filter options")
    
    def apply_filters(self):
        """Apply selected filters (2-6)"""
        if not self.data_processor.has_data('standard'):
            self.filter_status.configure(text="Please load and confirm a standard dataset first")
            return
            
        try:
            # Get selected values for each filter
            groups = list(self.grouping_selected)
            countries = list(self.country_selected)
            continents = list(self.continent_selected)
            rating_years = list(self.rating_year_selected)
            
            # Update buttons with number of selected items
            if groups:
                self.grouping_btn.configure(text=f"{len(groups)} items selected")
            else:
                self.grouping_btn.configure(text="Select grouping")
            
            if countries:
                self.country_btn.configure(text=f"{len(countries)} items selected")
            else:
                self.country_btn.configure(text="Select countries")
            
            if continents:
                self.continent_btn.configure(text=f"{len(continents)} items selected")
            else:
                self.continent_btn.configure(text="Select continents")
            
            if rating_years:
                self.rating_year_btn.configure(text=f"{len(rating_years)} items selected")
            else:
                self.rating_year_btn.configure(text="Select rating years")
            
            # Apply these filters to the data processor
            success, error = self.data_processor.apply_filters_to_both(
                groups=groups,
                countries=countries,
                continents=continents,
                rating_years=rating_years
            )
            
            if success:
                self.filter_status.configure(text="Filters applied successfully. Click 'Update Tables/Graphs' to see the results.")
                # Note: Intentionally NOT updating views here, waiting for user to click Update button
            else:
                raise Exception(error)
                
        except Exception as e:
            self.filter_status.configure(text=f"Error applying filters: {str(e)}")

    def reset_filters(self):
        """Reset all filters (2-7)"""
        if not self.data_processor.has_data('standard'):
            self.filter_status.configure(text="Please load and confirm a standard dataset first")
            return
                
        try:
            # Clear all filter selections
            self.grouping_selected = set()
            self.country_selected = set()
            self.continent_selected = set()
            self.rating_year_selected = set()
            
            # Reset button labels
            self.grouping_btn.configure(text="Select grouping")
            self.country_btn.configure(text="Select countries")
            self.continent_btn.configure(text="Select continents")
            self.rating_year_btn.configure(text="Select rating years")
            
            # Reset filters in the data processor
            success, error = self.data_processor.reset_filters()
            
            if success:
                # 필터 리셋 후 필터 옵션 목록을 갱신
                self.update_filter_options()
                
                # 필터가 리셋되었다는 메시지 표시 및 다음 단계 안내
                self.filter_status.configure(text="Filters reset successfully. Click 'Update Tables/Graphs' to update visualizations.")
                
                # 여기서 자동으로 업데이트하지 않음
            else:
                raise Exception(error)
                    
        except Exception as e:
            self.filter_status.configure(text=f"Error resetting filters: {str(e)}")
    
    def update_visualizations(self):
        """Update visualizations in other tabs (3-1)"""
        try:
            # 데이터가 선택되어 있는지 확인
            if not hasattr(self, 'selected_database') or not self.selected_dataset:
                self.control_status.configure(text="Please select and confirm a dataset first")
                return
            
            # 메인 애플리케이션 인스턴스 가져오기
            main_app = self.master.master.master
            
            # 디버깅을 위한 상태 출력
            print("\n======== DEBUG: UPDATE VISUALIZATIONS ========")
            print(f"Selected database: {self.selected_database}")
            print(f"Selected dataset: {self.selected_dataset}")
            print(f"Standard data available: {self.data_processor.has_data('standard')}")
            print(f"Claim data available: {self.data_processor.has_data('claim')}")
            
            # 업데이트 상태를 추적
            performance_updated = False
            claim_updated = False
            
            # Performance 탭 강제 업데이트 (standard 데이터 사용)
            if self.data_processor.has_data('standard'):
                print("Standard data exists - attempting to update Performance tab")
                
                # 현재 active_data_type 저장
                original_type = self.data_processor.active_data_type
                
                # active_data_type을 'standard'로 명시적 설정
                self.data_processor.active_data_type = 'standard'
                
                # Performance 탭 찾기 및 업데이트
                performance_tab = None
                for tab_name, tab in main_app.tabs.items():
                    if tab_name == 'Performance':
                        performance_tab = tab
                        break
                
                if performance_tab:
                    print("Found Performance tab - updating...")
                    performance_tab.update_view()
                    performance_updated = True
                    print("Performance tab update completed")
                else:
                    print("ERROR: Performance tab not found!")
                
                # active_data_type 복원
                self.data_processor.active_data_type = original_type
            else:
                print("No standard data available - skipping Performance tab update")
            
            # Claim 탭 강제 업데이트 (claim 데이터 사용)
            if self.data_processor.has_data('claim'):
                print("Claim data exists - attempting to update Claim tab")
                
                # 현재 active_data_type 저장
                original_type = self.data_processor.active_data_type
                
                # active_data_type을 'claim'으로 명시적 설정
                self.data_processor.active_data_type = 'claim'
                
                # Claim 탭 찾기 및 업데이트
                claim_tab = None
                for tab_name, tab in main_app.tabs.items():
                    if tab_name == 'Claim':
                        claim_tab = tab
                        break
                
                if claim_tab:
                    print("Found Claim tab - updating...")
                    claim_tab.update_view()
                    claim_updated = True
                    print("Claim tab update completed")
                else:
                    print("ERROR: Claim tab not found!")
                
                # active_data_type 복원
                self.data_processor.active_data_type = original_type
            else:
                print("No claim data available - skipping Claim tab update")
                
            # 상관관계 탭 업데이트 (두 데이터가 모두 필요할 경우)
            correlation_updated = False
            if self.data_processor.has_data('standard') and self.data_processor.has_data('claim'):
                print("Both data types exist - attempting to update Correlation tab")
                
                # Correlation 탭 찾기 및 업데이트
                correlation_tab = None
                for tab_name, tab in main_app.tabs.items():
                    if tab_name == 'Correlation':
                        correlation_tab = tab
                        break
                
                if correlation_tab:
                    print("Found Correlation tab - updating...")
                    correlation_tab.update_view()
                    correlation_updated = True
                    print("Correlation tab update completed")
                else:
                    print("ERROR: Correlation tab not found!")
            
            # 상태 메시지 업데이트
            update_messages = []
            if performance_updated:
                update_messages.append("Performance")
            if claim_updated:
                update_messages.append("Claim")
            if correlation_updated:
                update_messages.append("Correlation")
            
            if update_messages:
                tabs_str = " and ".join(update_messages)
                status_msg = f"{tabs_str} tables and graphs updated successfully"
                print(f"Update status message: {status_msg}")
                self.control_status.configure(text=status_msg)
            else:
                self.control_status.configure(text="No data available to update tables and graphs")
                
            print("======== DEBUG: UPDATE COMPLETE ========\n")
                
        except Exception as e:
            self.control_status.configure(text=f"Error updating tables and graphs: {str(e)}")
            import traceback
            print(f"Error updating visualizations: {str(e)}")
            print(traceback.format_exc())
    
    def download_excel(self):
        """Download data in Excel template (3-2)"""
        try:
            # Check if data is selected
            if not hasattr(self, 'selected_dataset') or not self.selected_dataset:
                self.control_status.configure(text="Please select and confirm a dataset first")
                return
            
            # Ask for save location
            file_path = filedialog.asksaveasfilename(
                defaultextension=".xlsx",
                filetypes=[("Excel files", "*.xlsx")],
                title="Save Excel Report"
            )
            
            if not file_path:
                return  # User cancelled
                
            # In a real application, you would:
            # 1. Load the Excel template
            # 2. Fill it with filtered data
            # 3. Save to the chosen location
            
            # For now, simulate success
            self.control_status.configure(text=f"Excel report saved to: {file_path}")
            
        except Exception as e:
            self.control_status.configure(text=f"Error downloading Excel report: {str(e)}")
    
    def update_view(self):
        """Required method for BaseTab compatibility"""
        # This can be empty or perform any initialization needed when tab is shown
        pass

# gui/tabs/performance_tab.py
from .base_tab import BaseTab
import customtkinter as ctk
import tkinter as tk
from tkinter import ttk
import numpy as np
from utils.plot_utils import PlotUtils
import matplotlib.pyplot as plt
import pandas as pd

class PerformanceTab(BaseTab):
    def setup_ui(self):
        """Setup Performance tab UI components with table + graph layout"""
        # Scrollable container
        self.scrollable_frame = ctk.CTkScrollableFrame(self)
        self.scrollable_frame.pack(fill="both", expand=True, padx=2, pady=2)

        # Create all visualization sections (table + graph pairs)
        self.create_visualization_sections()

    def create_visualization_sections(self):
        """Create all visualization sections with tables and graphs"""
        # Dictionary to store all UI elements
        self.sections = {}
        
        # Create sections for each visualization
        self.create_section("age", "Performance by Age Group")
        self.create_section("amount", "Performance Amount Distribution")
        self.create_section("diagnosis", "Performance by Category")
        self.create_section("monthly_trend", "Monthly Performance Trend")
        self.create_section("yearly_trend", "Yearly Performance Trend")
        self.create_section("avg_amount", "Average Performance by Age")
        self.create_section("gender", "Performance by Gender")
        self.create_section("seasonal", "Seasonal Performance Pattern")

    def create_section(self, section_id, title):
        """Create a section with table (left) and graph (right)"""
        # Main section container
        section_frame = ctk.CTkFrame(self.scrollable_frame)
        section_frame.pack(fill="x", expand=True, padx=5, pady=10)
        
        # Title for the section
        title_label = ctk.CTkLabel(
            section_frame,
            text=title,
            font=("Helvetica", 16, "bold")
        )
        title_label.pack(pady=5)
        
        # Container for table and graph
        content_frame = ctk.CTkFrame(section_frame)
        content_frame.pack(fill="x", expand=True, padx=5, pady=5)
        content_frame.grid_columnconfigure(0, weight=1)
        content_frame.grid_columnconfigure(1, weight=1)
        
        # Create table (left side)
        table_frame = ctk.CTkFrame(content_frame)
        table_frame.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)
        
        # Create treeview for table
        tree_frame = ctk.CTkFrame(table_frame)
        tree_frame.pack(fill="both", expand=True, padx=5, pady=5)
        
        tree = ttk.Treeview(tree_frame)
        tree.pack(side="left", fill="both", expand=True)
        
        # Add scrollbar to table
        scrollbar = ttk.Scrollbar(tree_frame, orient="vertical", command=tree.yview)
        scrollbar.pack(side="right", fill="y")
        tree.configure(yscrollcommand=scrollbar.set)
        
        # Configure dark style for treeview
        style = ttk.Style()
        style.configure("Treeview", 
                        background="#2B2B2B",
                        foreground="white",
                        fieldbackground="#2B2B2B")
        style.map('Treeview', 
                 background=[('selected', '#347083')])
        
        # Create graph (right side)
        graph_dict = self.create_graph_frame(content_frame, "", row=0, column=1)
        
        # Store references to UI elements
        self.sections[section_id] = {
            "frame": section_frame,
            "table": tree,
            "graph": graph_dict
        }

    def update_view(self):
        """Update all performance visualizations"""
        # Debug message
        print("\n======== DEBUG: PERFORMANCE TAB UPDATE_VIEW ========")
        print(f"Current active_data_type: {self.data_processor.active_data_type}")
        print(f"Standard data available: {self.data_processor.has_data('standard')}")
        
        if not self.data_processor.has_data('standard'):
            print("No standard data available to update Performance visualizations")
            print("======== DEBUG: PERFORMANCE UPDATE SKIPPED ========\n")
            return

        try:
            # Always use standard data
            original_type = self.data_processor.active_data_type
            self.data_processor.active_data_type = 'standard'
            print(f"Set active_data_type to 'standard' (was {original_type})")
            
            print("Updating performance visualizations...")
            self.update_age_distribution()
            print("- Age distribution updated")
            self.update_amount_distribution()
            print("- Amount distribution updated")
            self.update_diagnosis_distribution()
            print("- Diagnosis distribution updated")
            self.update_monthly_trend()
            print("- Monthly trend updated")
            self.update_yearly_trend()
            print("- Yearly trend updated")
            self.update_average_amount()
            print("- Average amount updated")
            self.update_gender_distribution()
            print("- Gender distribution updated")
            self.update_seasonal_pattern()
            print("- Seasonal pattern updated")
            
            # Restore original data type
            self.data_processor.active_data_type = original_type
            print(f"Restored active_data_type to '{original_type}'")
            print("======== DEBUG: PERFORMANCE UPDATE COMPLETE ========\n")
            
        except Exception as e:
            print(f"Error updating Performance visualizations: {str(e)}")
            import traceback
            print(traceback.format_exc())
            print("======== DEBUG: PERFORMANCE UPDATE FAILED ========\n")
            raise e

    # def update_table(self, section_id, data):
    #     """Update table with data"""
    #     if section_id not in self.sections:
    #         return
            
    #     tree = self.sections[section_id]["table"]
        
    #     # Clear existing data
    #     tree.delete(*tree.get_children())
        
    #     # Reset columns
    #     for col in tree["columns"]:
    #         tree.heading(col, text="")
        
    #     if isinstance(data, pd.Series):
    #         # Convert series to dataframe
    #         data = data.reset_index()
    #         columns = data.columns.tolist()
            
    #         # Configure columns
    #         tree["columns"] = columns
    #         for col in columns:
    #             tree.heading(col, text=col)
            
    #         # Add data rows
    #         for i, row in data.iterrows():
    #             values = row.tolist()
    #             tree.insert("", "end", values=values)
                
    #     elif isinstance(data, pd.DataFrame):
    #         columns = data.columns.tolist()
            
    #         # Configure columns
    #         tree["columns"] = columns
    #         for col in columns:
    #             tree.heading(col, text=col)
            
    #         # Add data rows
    #         for i, row in data.iterrows():
    #             values = row.tolist()
    #             tree.insert("", "end", values=values)
                
    #     elif isinstance(data, np.ndarray):
    #         # For numpy arrays, create simple index
    #         tree["columns"] = ["Value"]
    #         tree.heading("Value", text="Value")
            
    #         for i, value in enumerate(data):
    #             tree.insert("", "end", values=[value])

    def update_age_distribution(self):
        """Update age distribution graph and table"""
        section_id = "age"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        age_dist = self.data_processor.get_age_distribution()
        if age_dist is not None:
            # Update table
            self.update_table(section_id, age_dist)
            
            # Update graph
            ax.bar(range(len(age_dist)), age_dist.values, color='skyblue')
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Performance Count')
            ax.set_xticks(range(len(age_dist)))
            ax.set_xticklabels(age_dist.index, rotation=45)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_amount_distribution(self):
        """Update amount distribution graph and table"""
        section_id = "amount"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        amount_data = self.data_processor.get_amount_distribution()
        if amount_data is not None:
            # Create a histogram and get bin data for the table
            counts, bins = np.histogram(amount_data, bins=50)
            bin_centers = 0.5 * (bins[:-1] + bins[1:])
            hist_data = pd.DataFrame({
                'Bin_Start': bins[:-1],
                'Bin_End': bins[1:],
                'Count': counts
            })
            
            # Update table
            self.update_table(section_id, hist_data)
            
            # Update graph
            ax.hist(amount_data, bins=50, color='lightgreen')
            ax.set_xlabel('Performance Amount')
            ax.set_ylabel('Frequency')
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_diagnosis_distribution(self):
        """Update diagnosis distribution graph and table"""
        section_id = "diagnosis"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        diagnosis_data = self.data_processor.get_diagnosis_distribution()
        if diagnosis_data is not None:
            # Update table
            self.update_table(section_id, diagnosis_data)
            
            # Update graph
            ax.barh(range(len(diagnosis_data)), diagnosis_data.values, color='salmon')
            ax.set_xlabel('Performance Count')
            ax.set_ylabel('Category')
            ax.set_yticks(range(len(diagnosis_data)))
            ax.set_yticklabels(diagnosis_data.index)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_monthly_trend(self):
        """Update monthly trend graph and table"""
        section_id = "monthly_trend"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        monthly_data = self.data_processor.get_monthly_trend()
        if monthly_data is not None:
            # Update table
            self.update_table(section_id, monthly_data)
            
            # Update graph
            ax.plot(range(len(monthly_data)), monthly_data.values, marker='o')
            ax.set_xlabel('Month')
            ax.set_ylabel('Performance Count')
            ax.set_xticks(range(len(monthly_data)))
            ax.set_xticklabels([str(p) for p in monthly_data.index], rotation=45)
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_yearly_trend(self):
        """Update yearly trend graph and table"""
        section_id = "yearly_trend"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        yearly_data = self.data_processor.get_yearly_trend()
        if yearly_data is not None:
            # Update table
            self.update_table(section_id, yearly_data)
            
            # Update graph
            ax1 = ax
            ax2 = ax1.twinx()
            
            x = range(len(yearly_data.index))
            bars = ax1.bar(x, yearly_data[('amount', 'count')],
                         color='lightblue', alpha=0.7)
            line = ax2.plot(x, yearly_data[('amount', 'mean')],
                          color='lightgreen', marker='o', linewidth=2)
            
            ax1.set_xlabel('Year')
            ax1.set_ylabel('Number of Cases', color='lightblue')
            ax2.set_ylabel('Average Performance Amount', color='lightgreen')
            
            ax1.set_xticks(x)
            ax1.set_xticklabels(yearly_data.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height):,}',
                        ha='center', va='bottom', color='white')
                
        PlotUtils.setup_dark_style(ax)
        PlotUtils.setup_dark_style(ax2)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_average_amount(self):
        """Update average amount by age graph and table"""
        section_id = "avg_amount"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        avg_by_age = self.data_processor.get_average_amount_by_age()
        if avg_by_age is not None:
            # Update table
            self.update_table(section_id, avg_by_age)
            
            # Update graph
            x = range(len(avg_by_age))
            bars = ax.bar(x, avg_by_age.values, color='lightblue')
            
            ax.set_xticks(x)
            ax.set_xticklabels(avg_by_age.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'${height:,.0f}',
                       ha='center', va='bottom', color='white')
                
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Average Performance Amount ($)')
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_gender_distribution(self):
        """Update gender distribution graph and table"""
        section_id = "gender"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        gender_data = self.data_processor.get_gender_distribution()
        if gender_data is not None:
            # Update table
            self.update_table(section_id, gender_data)
            
            # Group data by age_group
            age_groups = gender_data['age_group'].unique()
            n_groups = len(age_groups)
            
            bar_width = 0.35
            index = np.arange(n_groups)
            
            # Get data for males and females
            male_data = gender_data[gender_data['gender'] == 'M']['count'].values
            female_data = gender_data[gender_data['gender'] == 'F']['count'].values
            
            # Create bars
            ax.bar(index - bar_width/2, male_data, bar_width, 
                  label='Male', color='lightblue')
            ax.bar(index + bar_width/2, female_data, bar_width,
                  label='Female', color='lightpink')
            
            ax.set_xlabel('Age Group')
            ax.set_ylabel('Performance Count')
            ax.set_xticks(index)
            ax.set_xticklabels(age_groups, rotation=45)
            ax.legend()
            
        PlotUtils.setup_dark_style(ax)
        self.sections[section_id]["graph"]["canvas"].draw()

    def update_seasonal_pattern(self):
        """Update seasonal pattern graph and table"""
        section_id = "seasonal"
        ax = self.sections[section_id]["graph"]["ax"]
        ax.clear()
        
        seasonal_data = self.data_processor.get_seasonal_pattern()
        if seasonal_data is not None:
            # Update table
            self.update_table(section_id, seasonal_data)
            
            ax1 = ax
            ax2 = ax1.twinx()
            
            x = range(len(seasonal_data.index))
            bars = ax1.bar(x, seasonal_data[('amount', 'count')],
                         color='lightblue', alpha=0.7)
            line = ax2.plot(x, seasonal_data[('amount', 'mean')],
                          color='lightgreen', marker='o', linewidth=2)
            
            ax1.set_xlabel('Season')
            ax1.set_ylabel('Number of Cases', color='lightblue')
            ax2.set_ylabel('Average Amount', color='lightgreen')
            
            ax1.set_xticks(x)
            ax1.set_xticklabels(seasonal_data.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height):,}',
                        ha='center', va='bottom', color='white')
                
        PlotUtils.setup_dark_style(ax)
        PlotUtils.setup_dark_style(ax2)
        self.sections[section_id]["graph"]["canvas"].draw()

# utils/data_processor.py
import pandas as pd
import numpy as np
from pathlib import Path
import logging
from datetime import datetime
from scipy.stats import chi2_contingency
import sqlite3

def cramers_v(confusion_matrix):
    """
    Calculate Cramer's V correlation coefficient for categorical variables
    
    Args:
        confusion_matrix (numpy.ndarray): Contingency matrix
    
    Returns:
        float: Cramer's V coefficient
    """
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum()
    min_dim = min(confusion_matrix.shape) - 1
    return np.sqrt(chi2 / (n * min_dim))

class DataProcessor:
    def __init__(self):
        # Initialize logging
        self._setup_logging()
        
        # Initialize separate data storage for standard and claim
        self.standard_data = None
        self.original_standard_data = None
        self.claim_data = None
        self.original_claim_data = None
        
        # Current active data type
        self.active_data_type = None  # 'standard' or 'claim'
        
        # Define required columns
        self.required_columns = {
            'standard': ['group', 'country', 'continent', 'rating_year', 'start_year'],
            'claim': ['date', 'amount', 'diagnosis', 'age', 'gender']
        }
        
        # Initialize filter tracking
        self.current_filters = {
            'groups': [],
            'countries': [],
            'continents': [],
            'rating_years': [],
            'start_years': []
        }

        # 데이터베이스 폴더 경로 설정
        self.db_folder = Path('./database')
        self.standard_db_path = self.db_folder / 'standard' / 'standard.db'
        self.claim_db_path = self.db_folder / 'claim' / 'claim.db'
        
        # 데이터베이스 폴더가 없으면 생성
        for path in [self.db_folder, self.db_folder / 'standard', self.db_folder / 'claim']:
            if not path.exists():
                path.mkdir(parents=True, exist_ok=True)
        
        # SQLite 데이터베이스 연결 초기화
        self._initialize_database_connections()

    def _initialize_database_connections(self):
        """초기 데이터베이스 연결 및 테이블 스키마 확인"""
        # 스탠다드 데이터베이스 초기화
        self._ensure_db_exists(self.standard_db_path)
        
        # 클레임 데이터베이스 초기화
        self._ensure_db_exists(self.claim_db_path)

    def _ensure_db_exists(self, db_path):
        """데이터베이스 파일이 존재하는지 확인하고 없으면 생성"""
        if not db_path.parent.exists():
            db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # 데이터베이스 연결 생성 (파일이 없으면 자동 생성됨)
        conn = sqlite3.connect(db_path)
        conn.close()

    def save_to_database(self, data, data_type, table_name, username='Unknown'):
        """
        데이터프레임을 SQLite 데이터베이스에 저장
        
        Args:
            data (pandas.DataFrame): 저장할 데이터프레임
            data_type (str): 데이터 타입 ('standard' 또는 'claim')
            table_name (str): 테이블 이름 (사용자 입력)
            username (str, optional): 데이터를 저장한 사용자 이름. 기본값은 'Unknown'
            
        Returns:
            tuple: (success: bool, error_message: Optional[str])
        """
        try:
            # 테이블 이름 유효성 검사 (SQLite에서 허용되는 문자만 사용)
            import re
            safe_table_name = re.sub(r'[^\w]', '_', table_name)
            
            # 데이터베이스 경로 결정
            db_path = self.standard_db_path if data_type == 'standard' else self.claim_db_path
            
            # 데이터베이스 연결
            conn = sqlite3.connect(db_path)
            
            # 데이터프레임을 SQL 테이블로 저장
            data.to_sql(safe_table_name, conn, if_exists='replace', index=False)
            
            # 메타데이터 테이블이 없으면 생성
            conn.execute('''
                CREATE TABLE IF NOT EXISTS metadata (
                    table_name TEXT PRIMARY KEY,
                    display_name TEXT,
                    created_date TEXT,
                    rows INTEGER,
                    columns INTEGER,
                    column_names TEXT,
                    username TEXT
                )
            ''')
            
            # 메타데이터 삽입 또는 업데이트
            metadata = {
                'table_name': safe_table_name,
                'display_name': table_name,
                'created_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'rows': len(data),
                'columns': len(data.columns),
                'column_names': ','.join(data.columns),
                'username': username
            }
            
            placeholders = ', '.join(['?'] * len(metadata))
            columns = ', '.join(metadata.keys())
            values = tuple(metadata.values())
            
            conn.execute(f'''
                INSERT OR REPLACE INTO metadata ({columns})
                VALUES ({placeholders})
            ''', values)
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"데이터를 '{safe_table_name}' 테이블에 저장했습니다")
            return True, None
            
        except Exception as e:
            error_msg = f"데이터베이스 저장 오류: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg
        
    def load_from_database(self, data_type, table_name):
        """
        SQLite 데이터베이스에서 데이터 로드
        
        Args:
            data_type (str): 데이터 타입 ('standard' 또는 'claim')
            table_name (str): 테이블 이름
            
        Returns:
            tuple: (success: bool, data: Optional[pandas.DataFrame], error_message: Optional[str])
        """
        try:
            # 데이터베이스 경로 결정
            db_path = self.standard_db_path if data_type == 'standard' else self.claim_db_path
            
            # 데이터베이스 연결
            conn = sqlite3.connect(db_path)
            
            # 테이블 존재 확인
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                return False, None, f"테이블 '{table_name}'이 존재하지 않습니다"
            
            # 데이터 로드
            data = pd.read_sql(f"SELECT * FROM '{table_name}'", conn)
            conn.close()
            
            # 데이터 처리
            if data_type == 'standard':
                self.original_standard_data = data.copy()
                self.standard_data = data.copy()
                self.standard_data = self.process_standard_data(self.standard_data)
                self.active_data_type = 'standard'
            else:
                self.original_claim_data = data.copy()
                self.claim_data = data.copy()
                self.claim_data = self.process_claim_data(self.claim_data)
                self.active_data_type = 'claim'
            
            self.logger.info(f"'{table_name}'에서 {len(data)} 행을 로드했습니다")
            return True, data, None
            
        except Exception as e:
            error_msg = f"데이터베이스 로드 오류: {str(e)}"
            self.logger.error(error_msg)
            return False, None, error_msg
    
    def get_table_list(self, data_type):
        """
        데이터베이스의 테이블 목록 조회
        
        Args:
            data_type (str): 데이터 타입 ('standard' 또는 'claim')
            
        Returns:
            list: 테이블 정보 목록 [{name, display_name, date, rows, username}]
        """
        try:
            # 데이터베이스 경로 결정
            db_path = self.standard_db_path if data_type == 'standard' else self.claim_db_path
            
            # 데이터베이스 파일이 없으면 빈 목록 반환
            if not db_path.exists():
                return []
            
            # 데이터베이스 연결
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # 메타데이터 테이블 확인
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='metadata'")
            if cursor.fetchone():
                # 메타데이터에서 테이블 정보 가져오기
                cursor.execute("""
                    SELECT table_name, display_name, created_date, rows, username
                    FROM metadata
                    ORDER BY created_date DESC
                """)
                tables = [
                    {
                        'name': row[0],  # 실제 테이블 이름
                        'display_name': row[1],  # 표시용 이름
                        'date': row[2],  # 생성 날짜
                        'rows': row[3],   # 행 수
                        'username': row[4] or 'Unknown'  # 사용자 이름
                    }
                    for row in cursor.fetchall()
                ]
            else:
                # 메타데이터가 없으면 기본 테이블 목록만 가져오기
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name != 'metadata'")
                tables = [
                    {
                        'name': row[0],
                        'display_name': row[0],
                        'date': 'Unknown',
                        'rows': 0,
                        'username': 'Unknown'
                    }
                    for row in cursor.fetchall()
                ]
            
            conn.close()
            return tables
            
        except Exception as e:
            self.logger.error(f"테이블 목록 조회 오류: {str(e)}")
            return []

    def delete_from_database(self, data_type, table_name):
        """
        Delete a table from the SQLite database
        
        Args:
            data_type (str): Data type ('standard' or 'claim')
            table_name (str): Table name to delete
            
        Returns:
            tuple: (success: bool, error_message: Optional[str])
        """
        try:
            # Determine database path
            db_path = self.standard_db_path if data_type == 'standard' else self.claim_db_path
            
            # Connect to database
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # Check if table exists
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                return False, f"Table '{table_name}' does not exist"
            
            # Delete the table
            cursor.execute(f"DROP TABLE IF EXISTS '{table_name}'")
            
            # Remove from metadata if it exists
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='metadata'")
            if cursor.fetchone():
                cursor.execute("DELETE FROM metadata WHERE table_name=?", (table_name,))
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"Deleted table '{table_name}' from database")
            return True, None
            
        except Exception as e:
            error_msg = f"Error deleting from database: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def _setup_logging(self):
        """Setup logging configuration"""
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)

    def has_data(self, data_type=None):
        """
        Check if data is loaded
        
        Args:
            data_type (str): Type of data ('standard' or 'claim'), if None uses active_data_type
            
        Returns:
            bool: True if data is loaded and not empty, False otherwise
        """
        # 디버깅 정보 추가
        print(f"Checking for {data_type if data_type else 'active'} data")
        
        if data_type is None:
            data_type = self.active_data_type
            print(f"Using active_data_type: {data_type}")
        
        # 명시적으로 데이터 속성에 접근하여 검사
        if data_type == 'standard':
            has_data = self.standard_data is not None and not self.standard_data.empty
            print(f"Standard data check: {has_data}")
            if not has_data:
                print(f"  standard_data is None: {self.standard_data is None}")
                if self.standard_data is not None:
                    print(f"  standard_data is empty: {self.standard_data.empty}")
                    print(f"  standard_data shape: {self.standard_data.shape}")
            return has_data
        
        elif data_type == 'claim':
            has_data = self.claim_data is not None and not self.claim_data.empty
            print(f"Claim data check: {has_data}")
            if not has_data:
                print(f"  claim_data is None: {self.claim_data is None}")
                if self.claim_data is not None:
                    print(f"  claim_data is empty: {self.claim_data.empty}")
                    print(f"  claim_data shape: {self.claim_data.shape}")
            return has_data
        
        print(f"Unknown data type: {data_type}")
        return False

    def get_data(self, data_type=None):
        """Return current data"""
        if data_type is None:
            data_type = self.active_data_type
            
        if data_type == 'standard':
            return self.standard_data
        elif data_type == 'claim':
            return self.claim_data
        return None

    def load_file(self, file_path: str, data_type: str):
        """
        Load data from file
        
        Args:
            file_path (str): Path to the data file
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            tuple: (success: bool, error_message: Optional[str])
        """
        try:
            self.logger.info(f"Loading {data_type} file: {file_path}")
            path = Path(file_path)
            
            if not path.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            # Load data based on file extension
            if path.suffix.lower() == '.csv':
                data = pd.read_csv(file_path)
            elif path.suffix.lower() in ['.xlsx', '.xls']:
                data = pd.read_excel(file_path)
            else:
                raise ValueError(f"Unsupported file format: {path.suffix}")

            # Validate data
            self.validate_data(data, data_type)
            
            # Store data and process based on type
            if data_type == 'standard':
                self.original_standard_data = data.copy()
                self.standard_data = data.copy()
                # Apply standard-specific processing
                self.standard_data = self.process_standard_data(self.standard_data)
                self.active_data_type = 'standard'
            elif data_type == 'claim':
                self.original_claim_data = data.copy()
                self.claim_data = data.copy()
                # Apply claim-specific processing
                self.claim_data = self.process_claim_data(self.claim_data)
                self.active_data_type = 'claim'
            
            self.logger.info(f"{data_type} file loaded successfully")
            return True, None
            
        except Exception as e:
            error_msg = f"Error loading {data_type} file: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def validate_data(self, data, data_type):
        """
        Validate loaded data
        
        Args:
            data (pandas.DataFrame): Data to validate
            data_type (str): Type of data ('standard' or 'claim')
        """
        # Check required columns for the specific data type
        required_cols = self.required_columns.get(data_type, [])
        missing_columns = [col for col in required_cols if col not in data.columns]
        
        if missing_columns:
            raise ValueError(f"Missing required columns for {data_type} data: {', '.join(missing_columns)}")

    def process_standard_data(self, data=None):
        """
        Process standard data with specific transformations
        
        Args:
            data (pandas.DataFrame, optional): Data to process. If None, uses self.standard_data
            
        Returns:
            pandas.DataFrame: Processed standard data
        """
        if data is None:
            if self.standard_data is None:
                return None
            data = self.standard_data.copy()
        
        try:
            # Apply standard-specific processing
            if 'rating_year' in data.columns:
                data['rating_year'] = pd.to_numeric(data['rating_year'], errors='coerce')
            
            if 'start_year' in data.columns:
                data['start_year'] = pd.to_numeric(data['start_year'], errors='coerce')
            
            # Ensure string columns are strings and standardize case
            string_columns = ['group', 'country', 'continent']
            for col in string_columns:
                if col in data.columns:
                    data[col] = data[col].astype(str).str.strip()
                    
            # Remove any rows with NaN values in critical columns
            required_cols = self.required_columns.get('standard', [])
            existing_cols = [col for col in required_cols if col in data.columns]
            if existing_cols:
                data.dropna(subset=existing_cols, inplace=True)
            
            # Add any additional standard-specific processing here
            
            return data
        except Exception as e:
            self.logger.error(f"Error processing standard data: {str(e)}")
            return None

    def process_claim_data(self, data=None):
        """
        Process claim data with specific transformations
        
        Args:
            data (pandas.DataFrame, optional): Data to process. If None, uses self.claim_data
            
        Returns:
            pandas.DataFrame: Processed claim data
        """
        if data is None:
            if self.claim_data is None:
                return None
            data = data.copy()
        
        try:
            # Apply claim-specific processing
            if 'date' in data.columns:
                if not pd.api.types.is_datetime64_any_dtype(data['date']):
                    data['date'] = pd.to_datetime(data['date'], errors='coerce')
                    
            if 'amount' in data.columns:
                data['amount'] = pd.to_numeric(data['amount'], errors='coerce')
            
            # Create age groups if needed
            if 'age_group' not in data.columns and 'age' in data.columns:
                age_bins = [0, 18, 30, 45, 60, 100]
                age_labels = ['0-18', '19-30', '31-45', '46-60', '60+']
                data['age_group'] = pd.cut(
                    data['age'], 
                    bins=age_bins, 
                    labels=age_labels, 
                    right=False
                )
            
            # Create season column if not exists
            if 'season' not in data.columns and 'date' in data.columns:
                try:
                    data['season'] = data['date'].dt.month.map({
                        12: 'Winter', 1: 'Winter', 2: 'Winter',
                        3: 'Spring', 4: 'Spring', 5: 'Spring',
                        6: 'Summer', 7: 'Summer', 8: 'Summer',
                        9: 'Autumn', 10: 'Autumn', 11: 'Autumn'
                    })
                except:
                    pass
            
            # Remove any rows with NaN values in critical columns
            required_cols = self.required_columns.get('claim', [])
            existing_cols = [col for col in required_cols if col in data.columns]
            if existing_cols:
                data.dropna(subset=existing_cols, inplace=True)
            
            return data
        except Exception as e:
            self.logger.error(f"Error processing claim data: {str(e)}")
            return None

    def apply_filters_to_both(self, groups=None, countries=None, continents=None, 
                     rating_years=None, start_years=None):
        """
        Apply filters to both standard and claim data
        """
        try:
            # Check if standard data is loaded
            if not self.has_data('standard'):
                raise ValueError("No standard data loaded")
            
            # Check if claim data is loaded
            claim_data_loaded = self.has_data('claim')
            
            self.logger.info("Applying filters to both standard and claim data...")
                
            # Save current filters
            self.current_filters = {
                'groups': groups or [],
                'countries': countries or [],
                'continents': continents or [],
                'rating_years': [int(year) for year in (rating_years or []) if year],
                'start_years': [int(year) for year in (start_years or []) if year]
            }

            # Start with original standard data
            filtered_standard = self.original_standard_data.copy()
            
            # Apply filters to standard data
            temp_filtered = filtered_standard.copy()
            
            filter_applied = False
            
            # Apply each filter if selected
            for filter_name, filter_values in [
                ('group', groups),
                ('country', countries),
                ('continent', continents),
                ('rating_year', rating_years),
                ('start_year', start_years)
            ]:
                if filter_values and filter_name in temp_filtered.columns:
                    temp_filtered = temp_filtered[temp_filtered[filter_name].isin(filter_values)]
                    
                    if len(temp_filtered) > 0:
                        filtered_standard = temp_filtered.copy()
                        filter_applied = True
                    else:
                        self.logger.warning(f"{filter_name} filter would remove all data - skipping this filter")
            
            # Final check to ensure we haven't filtered out all data
            if len(filtered_standard) == 0:
                self.logger.warning("All filters combined would remove all data - using original dataset")
                filtered_standard = self.original_standard_data.copy()
                filter_applied = False

            # Update standard data and apply processing
            self.standard_data = self.process_standard_data(filtered_standard)
            
            # Handle claim data filtering
            if claim_data_loaded and filter_applied:
                filtered_claim = self.original_claim_data.copy()
                
                # Add filtering logic for claim data based on standard data filtering
                if 'policy_id' in filtered_standard.columns and 'policy_id' in filtered_claim.columns:
                    filtered_policy_ids = filtered_standard['policy_id'].unique()
                    filtered_claim = filtered_claim[filtered_claim['policy_id'].isin(filtered_policy_ids)]
                
                # Additional cross-dataset filtering if possible
                if countries and 'country' in filtered_claim.columns:
                    filtered_claim = filtered_claim[filtered_claim['country'].isin(countries)]
                
                if groups and 'group' in filtered_claim.columns:
                    filtered_claim = filtered_claim[filtered_claim['group'].isin(groups)]
                
                if continents and 'continent' in filtered_claim.columns:
                    filtered_claim = filtered_claim[filtered_claim['continent'].isin(continents)]
                
                # Final check for claim data
                if len(filtered_claim) == 0:
                    self.logger.warning("Claim filters would remove all data - using original claim dataset")
                    filtered_claim = self.original_claim_data.copy()
                
                # Update claim data and apply processing
                self.claim_data = self.process_claim_data(filtered_claim)
            
            self.logger.info("Filters applied successfully to both datasets")
            return True, None
            
        except Exception as e:
            error_msg = f"Error applying filters: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def reset_filters(self):
        """
        Reset all filters
        
        Returns:
            tuple: (success: bool, error_message: Optional[str])
        """
        try:
            self.logger.info("Resetting all filters")
            
            # Reset current filters
            self.current_filters = {
                'groups': [],
                'countries': [],
                'continents': [],
                'rating_years': [],
                'start_years': []
            }
            
            # Restore original data
            if self.original_standard_data is not None:
                self.standard_data = self.original_standard_data.copy()
                # Apply standard processing to restored data
                self.standard_data = self.process_standard_data(self.standard_data)
            
            if self.original_claim_data is not None:
                self.claim_data = self.original_claim_data.copy()
                # Apply claim processing to restored data
                self.claim_data = self.process_claim_data(self.claim_data)
            
            self.logger.info("Filters reset successfully")
            return True, None
            
        except Exception as e:
            error_msg = f"Error resetting filters: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def get_filter_summary(self):
        """
        Get summary of currently applied filters
        
        Returns:
            str: Summary of applied filters
        """
        summary = []
        
        for filter_name, values in self.current_filters.items():
            if values:
                summary.append(f"{filter_name.capitalize()}: {', '.join(map(str, values))}")
        
        if not summary:
            return "No filters applied"
        
        return "\n".join(summary)

    def get_unique_values(self, column, data_type=None):
        """
        Get unique values for a given column
        
        Args:
            column (str): Column name
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            list: Sorted list of unique values
        """
        try:
            self.logger.info(f"Getting unique values for column: {column}, data_type: {data_type}")
            
            if data_type is None:
                data_type = self.active_data_type
                
            data = self.get_data(data_type)
            
            if data is not None and column in data.columns:
                unique_values = sorted(data[column].unique())
                self.logger.info(f"Found {len(unique_values)} unique values for {column}")
                return unique_values
            else:
                self.logger.warning(f"Column {column} not found in {data_type} data")
                return []
        except Exception as e:
            self.logger.error(f"Error getting unique values: {str(e)}")
            return []

    def get_filtered_data_summary(self, data_type=None):
        """
        Get summary statistics of filtered data
        
        Args:
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            str: Summary statistics text
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return f"No {data_type} data available"

        summary = []
        summary.append(f"Total Records: {len(data):,}")
        
        if data_type == 'standard':
            # Group counts
            if 'group' in data.columns:
                group_counts = data['group'].value_counts()
                summary.append("\nGroup Distribution:")
                for group, count in group_counts.items():
                    summary.append(f"{group}: {count:,}")
            
            # Country counts
            if 'country' in data.columns:
                country_counts = data['country'].value_counts().head(10)
                summary.append("\nTop 10 Countries:")
                for country, count in country_counts.items():
                    summary.append(f"{country}: {count:,}")
            
            # Year distribution
            if 'rating_year' in data.columns:
                year_counts = data['rating_year'].value_counts().sort_index()
                summary.append("\nRating Year Distribution:")
                for year, count in year_counts.items():
                    summary.append(f"{year}: {count:,}")
        
        elif data_type == 'claim':
            # Age group distribution
            if 'age_group' in data.columns:
                age_counts = data['age_group'].value_counts()
                summary.append("\nAge Group Distribution:")
                for age, count in age_counts.items():
                    summary.append(f"{age}: {count:,}")
            
            # Diagnosis distribution
            if 'diagnosis' in data.columns:
                diag_counts = data['diagnosis'].value_counts().head(10)
                summary.append("\nTop 10 Diagnoses:")
                for diag, count in diag_counts.items():
                    summary.append(f"{diag}: {count:,}")
            
            # Amount statistics
            if 'amount' in data.columns:
                summary.append("\nAmount Statistics:")
                summary.append(f"Average: ${data['amount'].mean():,.2f}")
                summary.append(f"Median: ${data['amount'].median():,.2f}")
                summary.append(f"Min: ${data['amount'].min():,.2f}")
                summary.append(f"Max: ${data['amount'].max():,.2f}")

        return "\n".join(summary)

    def export_filtered_data(self, file_path, data_type=None):
        """
        Export filtered data to file
        
        Args:
            file_path (str): Path where to save the file
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            tuple: (success: bool, error_message: Optional[str])
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        try:
            if data is None:
                raise ValueError(f"No {data_type} data available to export")

            self.logger.info(f"Exporting {data_type} data to: {file_path}")
            
            path = Path(file_path)
            if path.suffix.lower() == '.csv':
                data.to_csv(file_path, index=False)
            elif path.suffix.lower() in ['.xlsx', '.xls']:
                data.to_excel(file_path, index=False)
            else:
                raise ValueError(f"Unsupported export format: {path.suffix}")
            
            self.logger.info(f"{data_type} data exported successfully")
            return True, None
            
        except Exception as e:
            error_msg = f"Error exporting data: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg

    def get_data_statistics(self, data_type=None):
        """
        Get comprehensive statistics about the data
        
        Args:
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            dict: Dictionary containing various statistics
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        original_data = self.original_standard_data if data_type == 'standard' else self.original_claim_data
        
        if data is None:
            return {"error": f"No {data_type} data available"}

        try:
            stats = {
                "data_type": data_type,
                "total_records": len(data),
                "total_records_original": len(original_data) if original_data is not None else 0,
                "filtered_percentage": (len(data) / len(original_data) * 100) if original_data is not None else 100,
            }
            
            if data_type == 'standard':
                stats.update({
                    "groups": data['group'].value_counts().to_dict() if 'group' in data.columns else {},
                    "countries": data['country'].value_counts().to_dict() if 'country' in data.columns else {},
                    "continents": data['continent'].value_counts().to_dict() if 'continent' in data.columns else {},
                    "rating_years": data['rating_year'].value_counts().sort_index().to_dict() if 'rating_year' in data.columns else {},
                    "start_years": data['start_year'].value_counts().sort_index().to_dict() if 'start_year' in data.columns else {},
                    "current_filters": self.current_filters
                })
            
            elif data_type == 'claim':
                stats.update({
                    "age_groups": data['age_group'].value_counts().to_dict() if 'age_group' in data.columns else {},
                    "diagnoses": data['diagnosis'].value_counts().head(10).to_dict() if 'diagnosis' in data.columns else {},
                    "gender": data['gender'].value_counts().to_dict() if 'gender' in data.columns else {},
                    "amount_stats": {
                        "mean": data['amount'].mean() if 'amount' in data.columns else None,
                        "median": data['amount'].median() if 'amount' in data.columns else None,
                        "min": data['amount'].min() if 'amount' in data.columns else None,
                        "max": data['amount'].max() if 'amount' in data.columns else None
                    }
                })
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Error calculating statistics: {str(e)}")
            return {"error": str(e)}

    def get_correlation_matrix(self, data_type=None):
        """
        Calculate correlation matrix for categorical variables using Cramer's V
        
        Args:
            data_type (str): Type of data ('standard' or 'claim')
            
        Returns:
            pandas.DataFrame: Correlation matrix
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Select appropriate categorical columns based on data type
        if data_type == 'standard':
            cat_columns = ['group', 'country', 'continent']
        else:  # claim
            cat_columns = ['age_group', 'gender', 'diagnosis', 'season']
        
        # Ensure all selected columns exist in the dataframe
        available_columns = [col for col in cat_columns if col in data.columns]
        
        if len(available_columns) < 2:
            return None
        
        # Preprocessing: ensure age_group exists if age is in available columns
        if 'age' in available_columns and 'age_group' not in available_columns:
            age_bins = [0, 18, 30, 45, 60, 100]
            age_labels = ['0-18', '19-30', '31-45', '46-60', '60+']
            data['age_group'] = pd.cut(
                data['age'], 
                bins=age_bins, 
                labels=age_labels, 
                right=False
            )
            available_columns = [col if col != 'age' else 'age_group' for col in available_columns]
        
        # Create correlation matrix
        correlation_matrix = pd.DataFrame(
            index=available_columns, 
            columns=available_columns, 
            dtype=float
        )
        
        # Calculate Cramer's V for each pair of categorical variables
        for i, col1 in enumerate(available_columns):
            for j, col2 in enumerate(available_columns):
                if i == j:
                    correlation_matrix.loc[col1, col2] = 1.0
                elif i < j:
                    # Create contingency table
                    contingency_table = pd.crosstab(data[col1], data[col2])
                    
                    # Calculate Cramer's V
                    cramer_v = cramers_v(contingency_table.values)
                    
                    # Store in symmetric matrix
                    correlation_matrix.loc[col1, col2] = cramer_v
                    correlation_matrix.loc[col2, col1] = cramer_v
        
        return correlation_matrix

    def get_age_distribution(self, data_type=None):
        """
        Calculate age distribution
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.Series: Age group distribution
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Ensure age groups exist
        if 'age_group' not in data.columns and 'age' in data.columns:
            age_bins = [0, 18, 30, 45, 60, 100]
            age_labels = ['0-18', '19-30', '31-45', '46-60', '60+']
            data['age_group'] = pd.cut(
                data['age'], 
                bins=age_bins, 
                labels=age_labels, 
                right=False
            )
        
        if 'age_group' in data.columns:
            return data['age_group'].value_counts().sort_index()
        
        return None

    def get_amount_distribution(self, data_type=None):
        """
        Get distribution of amounts
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            numpy.array or None: Array of amounts
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Return amount column if it exists
        return data.get('amount', pd.Series()).values

    def get_diagnosis_distribution(self, data_type=None):
        """
        Calculate diagnosis distribution
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.Series: Diagnosis distribution
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None or 'diagnosis' not in data.columns:
            return None
        
        return data['diagnosis'].value_counts().head(10)

    def get_monthly_trend(self, data_type=None):
        """
        Calculate monthly trend
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.Series: Monthly trend
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Extract monthly trend from date
        if 'date' in data.columns:
            try:
                if not pd.api.types.is_datetime64_any_dtype(data['date']):
                    dates = pd.to_datetime(data['date'], errors='coerce')
                else:
                    dates = data['date']
                return dates.dt.to_period('M').value_counts().sort_index()
            except Exception as e:
                self.logger.error(f"Error processing date column: {e}")
                return None
        elif 'month' in data.columns:
            return data['month'].value_counts().sort_index()
        else:
            return None

    def get_yearly_trend(self, data_type=None):
        """
        Calculate yearly trend with amount statistics
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.DataFrame: Yearly trend with count and mean amount
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Determine year column based on data type
        if data_type == 'standard':
            year_col = 'rating_year' if 'rating_year' in data.columns else 'year'
        else:  # claim
            year_col = 'year'
            if year_col not in data.columns and 'date' in data.columns:
                try:
                    if not pd.api.types.is_datetime64_any_dtype(data['date']):
                        data['year'] = pd.to_datetime(data['date'], errors='coerce').dt.year
                    else:
                        data['year'] = data['date'].dt.year
                    year_col = 'year'
                except:
                    return None
        
        # Check if year column exists
        if year_col not in data.columns:
            return None
            
        # Get amount column if it exists
        amount_col = 'amount' if 'amount' in data.columns else None
        
        if amount_col:
            return data.groupby(year_col).agg({
                amount_col: ['count', 'mean']
            })
        else:
            return pd.DataFrame(data[year_col].value_counts().sort_index())

    def get_average_amount_by_age(self, data_type=None):
        """
        Calculate average amount by age group
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.Series: Average amount by age group
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Create age groups if needed
        if 'age_group' not in data.columns and 'age' in data.columns:
            age_bins = [0, 18, 30, 45, 60, 100]
            age_labels = ['0-18', '19-30', '31-45', '46-60', '60+']
            data['age_group'] = pd.cut(
                data['age'], 
                bins=age_bins, 
                labels=age_labels, 
                right=False
            )
        
        # Check for age_group and amount columns
        if 'age_group' not in data.columns or 'amount' not in data.columns:
            return None
            
        # Add observed=True to suppress the warning
        return data.groupby('age_group', observed=True)['amount'].mean()

    def get_gender_distribution(self, data_type=None):
        """
        Calculate gender distribution by age group
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.DataFrame: Gender distribution
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Create age groups if needed
        if 'age_group' not in data.columns and 'age' in data.columns:
            age_bins = [0, 18, 30, 45, 60, 100]
            age_labels = ['0-18', '19-30', '31-45', '46-60', '60+']
            data['age_group'] = pd.cut(
                data['age'], 
                bins=age_bins, 
                labels=age_labels, 
                right=False
            )
        
        # Check for required columns
        if 'gender' not in data.columns or 'age_group' not in data.columns:
            return None
        
        # Add observed=True to suppress the warning
        return data.groupby(['age_group', 'gender'], observed=True).size().reset_index(name='count')

    def get_seasonal_pattern(self, data_type=None):
        """
        Calculate seasonal pattern
        
        Args:
            data_type (str): Type of data (default to active type)
            
        Returns:
            pandas.DataFrame: Seasonal pattern with count and mean amount
        """
        if data_type is None:
            data_type = self.active_data_type
            
        data = self.get_data(data_type)
        
        if data is None:
            return None
        
        # Add season column if not exists
        if 'season' not in data.columns and 'date' in data.columns:
            try:
                if not pd.api.types.is_datetime64_any_dtype(data['date']):
                    date_col = pd.to_datetime(data['date'], errors='coerce')
                else:
                    date_col = data['date']
                    
                data['season'] = date_col.dt.month.map({
                    12: 'Winter', 1: 'Winter', 2: 'Winter',
                    3: 'Spring', 4: 'Spring', 5: 'Spring',
                    6: 'Summer', 7: 'Summer', 8: 'Summer',
                    9: 'Autumn', 10: 'Autumn', 11: 'Autumn'
                })
            except Exception as e:
                self.logger.error(f"Error processing date column: {e}")
                return None
        
        # Check for required columns
        if 'season' not in data.columns:
            return None
            
        # Get amount column if it exists
        amount_col = 'amount' if 'amount' in data.columns else None
        
        if amount_col:
            return data.groupby('season').agg({
                amount_col: ['count', 'mean']
            })
        else:
            return pd.DataFrame(data['season'].value_counts())

# utils/plot_utils.py
import matplotlib.pyplot as plt
import seaborn as sns

class PlotUtils:
    @staticmethod
    def setup_dark_style(ax):
        """Setup dark style for matplotlib plots"""
        ax.set_facecolor('#2B2B2B')
        ax.tick_params(colors='white', labelsize=10)
        for spine in ax.spines.values():
            spine.set_color('white')
        ax.set_xlabel(ax.get_xlabel(), color='white')
        ax.set_ylabel(ax.get_ylabel(), color='white')
        if ax.get_title():
            ax.set_title(ax.get_title(), color='white', pad=20)

    @staticmethod
    def setup_figure(fig):
        """Setup figure for dark theme"""
        fig.patch.set_facecolor('#2B2B2B')
        fig.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.9)
